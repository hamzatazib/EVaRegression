{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T12:56:59.063000-05:00",
     "start_time": "2019-12-03T17:56:34.981Z"
    }
   },
   "outputs": [],
   "source": [
    "using JuMP, Gurobi, CSV, Random, StatsBase, LinearAlgebra, Distributions, DataFrames, Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T22:30:19.753000-05:00",
     "start_time": "2019-12-04T03:30:19.677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 13)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "train = CSV.read(\"../data/3. Housing/housing_train.csv\")\n",
    "test = CSV.read(\"../data/3. Housing/housing_test.csv\")\n",
    "\n",
    "#From DataFrames to Matrices\n",
    "#input data\n",
    "X = convert(Matrix, train[:,1:13])\n",
    "X_test = convert(Matrix, test[:,1:13])\n",
    "\n",
    "#demand\n",
    "Y = train[:, 14]\n",
    "Y_test = test[:,14]\n",
    "\n",
    "n, p = size(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T22:30:23.061000-05:00",
     "start_time": "2019-12-04T03:30:22.906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "regularized_least_squares (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function regularized_least_squares(X, Y, λ)\n",
    "    n,p = size(X)\n",
    "    model_rls = Model(solver=GurobiSolver(OutputFlag = 0))\n",
    "    @variable(model_rls, w[1:p])\n",
    "    @objective(\n",
    "        model_rls,\n",
    "        Min,\n",
    "        sum((Y[i] - dot(w, X[i,:]))^2 for i=1:n) + λ*w'w\n",
    "    )\n",
    "    solve(model_rls)\n",
    "    w_opt_rls = getvalue(w)\n",
    "    opt_obj_rls = getobjectivevalue(model_rls)\n",
    "    return w_opt_rls, opt_obj_rls\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T22:30:23.497000-05:00",
     "start_time": "2019-12-04T03:30:23.443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stable_reg_l2 (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function stable_reg_l2(X, Y, λ, k) \n",
    "    # k: number of points in training, K: number of classes, λ: Regularization coeff\n",
    "    n,p = size(X)\n",
    "    model_stable_reg = Model(solver=GurobiSolver(OutputFlag = 0))\n",
    "    @variable(model_stable_reg, w[1:p])\n",
    "    @variable(model_stable_reg, θ)\n",
    "    @variable(model_stable_reg, u[1:n] >= 0)\n",
    "    \n",
    "    @objective(\n",
    "        model_stable_reg, \n",
    "        Min, \n",
    "        λ*w'w + (k*θ + sum(u[i] for i=1:n))\n",
    "    )\n",
    "    \n",
    "    @constraint(\n",
    "        model_stable_reg, \n",
    "        [i=1:n], \n",
    "        u[i] + θ >= -(Y[i]-w'X[i,:])\n",
    "    )\n",
    "    @constraint(\n",
    "        model_stable_reg, \n",
    "        [i=1:n], \n",
    "        u[i] + θ >= (Y[i]-w'X[i,:])\n",
    "    )\n",
    "    solve(model_stable_reg)\n",
    "    w_opt = getvalue(w)\n",
    "    u_opt = getvalue(u)\n",
    "    θ_opt = getvalue(θ)\n",
    "    opt_obj = getobjectivevalue(model_stable_reg)\n",
    "    \n",
    "    return w_opt, u_opt, θ_opt, opt_obj\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVaR Regression Regularized\n",
    "$$\n",
    "\\min_{s, w} \\lambda ||w||^2 + s \\log \\left(\\frac{1}{n\\alpha} \\sum_{i=1}^n \\exp \\left(\\frac{(Y_i - w^\\top X_i)^2}{s}\\right) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\ell_2$ EVaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T22:30:25.431000-05:00",
     "start_time": "2019-12-04T03:30:25.363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∇wobjective_ℓ2 (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function objective_ℓ2(X,Y,s,w,α, λ)\n",
    "    \"\"\"\n",
    "    α: fraction of data that constitutes the training set ∈ [0,1]\n",
    "    \"\"\"\n",
    "    n = size(X)[1]\n",
    "    return λ*dot(w, w) + s*log(sum(exp(1/s*(dot(w,X[i,:])-Y[i])^2) for i=1:n)/(n*α))\n",
    "end\n",
    "\n",
    "function ∇sobjective_ℓ2(X,Y,s,w,α,λ) # Not affected bY λ but still putting it for function homogeneity issue\n",
    "    n = size(X)[1]\n",
    "    return log(sum(exp(1/s*(dot(w,X[i,:])-Y[i])^2) for i=1:n)/(n*α)) - sum(((dot(w,X[i,:])-Y[i])^2)*exp(1/s*(dot(w,X[i,:])-Y[i])^2) for i=1:n)/sum(exp(1/s*(dot(w,X[i,:])-Y[i])^2) for i=1:n)/s\n",
    "end\n",
    "\n",
    "function ∇wobjective_ℓ2(X,Y,s,w,α,λ)\n",
    "    n = size(X)[1]\n",
    "    return 2*λ*w + 2*sum(((dot(w,X[i,:])-Y[i]))*exp(1/s*(dot(w,X[i,:])-Y[i])^2)*X[i,:] for i=1:n)/sum(exp(1/s*(dot(w,X[i,:])-Y[i])^2) for i=1:n)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T22:30:25.538000-05:00",
     "start_time": "2019-12-04T03:30:25.516Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gradient_descent_EVaR_ℓ2 (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gradient_descent_EVaR_ℓ2(X, Y, s_0, w_0, α, λ, c_s, c_w, ε)\n",
    "    \"\"\"\n",
    "    c_s: constant learning rate associated to the ∇ w.r.t s\n",
    "    c_w: constant learning rate associated to the ∇ w.r.t w\n",
    "    ε: \n",
    "    \"\"\"\n",
    "    #println(objective_ℓ2(X,Y,s_0,w_0,α,λ))\n",
    "    list_f = [objective_ℓ2(X,Y,s_0,w_0,α,λ)]\n",
    "    s=s_0; w=w_0\n",
    "    n_grad = dot(∇wobjective_ℓ2(X,Y,s,w,α,λ), ∇wobjective_ℓ2(X,Y,s,w,α,λ)) + dot(∇sobjective_ℓ2(X,Y,s,w,α,λ),∇sobjective_ℓ2(X,Y,s,w,α,λ))\n",
    "    k = 1\n",
    "    while n_grad > ε\n",
    "        s = s - c_s*∇sobjective_ℓ2(X,Y,s,w,α,λ)\n",
    "        s = max(0.000000001,s)\n",
    "        w = w - c_w*∇wobjective_ℓ2(X,Y,s,w,α,λ)\n",
    "        n_grad = dot(∇wobjective_ℓ2(X,Y,s,w,α,λ), ∇wobjective_ℓ2(X,Y,s,w,α,λ)) + dot(∇sobjective_ℓ2(X,Y,s,w,α,λ),∇sobjective_ℓ2(X,Y,s,w,α,λ))\n",
    "        push!(list_f, objective_ℓ2(X,Y,s,w,α,λ))\n",
    "        if k == 30000\n",
    "            break\n",
    "        end\n",
    "        k += 1\n",
    "    end\n",
    "    list_f, s, w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T22:30:25.608000-05:00",
     "start_time": "2019-12-04T03:30:25.601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nesterov_gradient_descent_EVaR_ℓ2 (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To be implemented\n",
    "function nesterov_gradient_descent_EVaR_ℓ2()\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\ell_1$ EVaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T22:30:28.368000-05:00",
     "start_time": "2019-12-04T03:30:28.329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∇wobjective_ℓ1 (generic function with 1 method)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function objective_ℓ1(X,Y,s,w,α, λ)\n",
    "    \"\"\"\n",
    "    α: fraction of data that constitutes the training set ∈ [0,1]\n",
    "    \"\"\"\n",
    "    n = size(X)[1]\n",
    "    return λ*dot(w, w) + s*log(sum(exp(1/s*abs(dot(w,X[i,:])-Y[i])) for i=1:n)/(n*α))\n",
    "end\n",
    "\n",
    "function ∇sobjective_ℓ1(X,Y,s,w,α,λ) # Not affected bY λ but still putting it for function homogeneity issue\n",
    "    n = size(X)[1]\n",
    "    return log(sum(exp(1/s*abs(dot(w,X[i,:])-Y[i])) for i=1:n)/(n*α)) - sum(abs(dot(w,X[i,:])-Y[i])*exp(1/s*(abs(dot(w,X[i,:])-Y[i]))) for i=1:n)/sum(exp(1/s*abs(dot(w,X[i,:])-Y[i])) for i=1:n)/s\n",
    "end\n",
    "\n",
    "function ∇wobjective_ℓ1(X,Y,s,w,α,λ)\n",
    "    n = size(X)[1]\n",
    "    return 2*λ*w + sum(sign.((dot(w,X[i,:])-Y[i]))*exp(1/s*(abs(dot(w,X[i,:])-Y[i])))*X[i,:] for i=1:n)/sum(exp(1/s*(abs(dot(w,X[i,:])-Y[i]))) for i=1:n)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T22:30:28.545000-05:00",
     "start_time": "2019-12-04T03:30:28.515Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gradient_descent_EVaR_ℓ1 (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gradient_descent_EVaR_ℓ1(X, Y, s_0, w_0, α, λ, c_s, c_w, ε)\n",
    "    \"\"\"\n",
    "    c_s: constant learning rate associated to the ∇ w.r.t s\n",
    "    c_w: constant learning rate associated to the ∇ w.r.t w\n",
    "    ε: \n",
    "    \"\"\"\n",
    "    #println(objective_ℓ1(X,Y,s_0,w_0,α,λ))\n",
    "    list_f = [objective_ℓ1(X,Y,s_0,w_0,α,λ)]\n",
    "    s=s_0; w=w_0\n",
    "    n_grad = dot(∇wobjective_ℓ1(X,Y,s,w,α,λ), ∇wobjective_ℓ1(X,Y,s,w,α,λ)) + dot(∇sobjective_ℓ1(X,Y,s,w,α,λ),∇sobjective_ℓ1(X,Y,s,w,α,λ))\n",
    "    k=1\n",
    "    while n_grad > ε\n",
    "        s = s - c_s*∇sobjective_ℓ1(X,Y,s,w,α,λ)\n",
    "        s = max(0.000000001,s)\n",
    "        w = w - c_w*∇wobjective_ℓ1(X,Y,s,w,α,λ)\n",
    "        n_grad = dot(∇wobjective_ℓ1(X,Y,s,w,α,λ), ∇wobjective_ℓ1(X,Y,s,w,α,λ)) + dot(∇sobjective_ℓ1(X,Y,s,w,α,λ),∇sobjective_ℓ1(X,Y,s,w,α,λ))\n",
    "        push!(list_f, objective_ℓ1(X,Y,s,w,α,λ))\n",
    "        if k == 30000\n",
    "            break\n",
    "        end\n",
    "        k += 1\n",
    "    end\n",
    "    list_f, s, w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T22:30:28.619000-05:00",
     "start_time": "2019-12-04T03:30:28.612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nesterov_gradient_descent_EVaR_ℓ1 (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To be implemented\n",
    "function nesterov_gradient_descent_EVaR_ℓ1()\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation & Hyperparameter tuning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T22:30:50.962000-05:00",
     "start_time": "2019-12-04T03:30:50.943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_MAE (generic function with 1 method)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fit_least_squares(X_i, Y_i, w_opt)\n",
    "    return (Y_i - dot(w_opt, X_i))^2\n",
    "end\n",
    "\n",
    "function fit_least_absolute_values(X_i, Y_i, w_opt)\n",
    "    return abs(Y_i - dot(w_opt, X_i))\n",
    "end\n",
    "\n",
    "function calculate_MSE(X, Y, w_opt)\n",
    "    return mean((X*w_opt-Y).^2)\n",
    "end\n",
    "\n",
    "function calculate_MAE(X, Y, w_opt)\n",
    "    return mean(broadcast(abs, X*w_opt-Y))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T22:30:51.160000-05:00",
     "start_time": "2019-12-04T03:30:51.119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_training_and_validation_indices (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_training_and_validation_indices(X, Y, w_opt, train_is_worse, k)\n",
    "    \"\"\"\n",
    "    train_is_worse: boolean, true if the training set contains the worst errors, false if it's the validation\n",
    "    k: number of observations in the training set\n",
    "    \"\"\"\n",
    "    n,p = size(X)\n",
    "    least_squares_df = DataFrame()\n",
    "    least_squares_df.Obs_Index = 1:n\n",
    "    least_squares_df.LS_Value = [fit_least_squares(X[i,:], Y[i], w_opt) for i=1:n]\n",
    "    least_squares_sorted = sort!(least_squares_df, :LS_Value, rev=true)\n",
    "    if train_is_worse == true\n",
    "        train_indices = least_squares_sorted[1:k, :Obs_Index]\n",
    "        val_indices = least_squares_sorted[k+1:n, :Obs_Index]\n",
    "    else\n",
    "        val_indices = least_squares_sorted[1:k, :Obs_Index]\n",
    "        train_indices = least_squares_sorted[k+1:n, :Obs_Index]\n",
    "    end\n",
    "    \n",
    "    return train_indices, val_indices\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the Regressions (Housing Dataset) - 70/30 Train/Val splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best RLS - Random Train/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T22:32:16.090000-05:00",
     "start_time": "2019-12-04T03:32:13.863Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained 70/30 train/val random split for RLS\n",
      "Academic license - for non-commercial use only\n",
      "λ=0.0\t MSE=0.3366626272045661\n",
      "Academic license - for non-commercial use only\n",
      "λ=0.01\t MSE=0.3366491298677666\n",
      "Academic license - for non-commercial use only\n",
      "λ=0.1\t MSE=0.3365297101205204\n",
      "Academic license - for non-commercial use only\n",
      "λ=0.5\t MSE=0.33604093190937495\n",
      "Academic license - for non-commercial use only\n",
      "λ=1.0\t MSE=0.33551534750013484\n",
      "Academic license - for non-commercial use only\n",
      "λ=5.0\t MSE=0.33351238545740275\n",
      "Academic license - for non-commercial use only\n",
      "λ=10.0\t MSE=0.33409683439503274\n",
      "Academic license - for non-commercial use only\n",
      "λ=20.0\t MSE=0.3402322857248903\n",
      "Academic license - for non-commercial use only\n",
      "λ=30.0\t MSE=0.3496109941058661\n",
      "Academic license - for non-commercial use only\n",
      "λ=40.0\t MSE=0.3604313883641149\n",
      "Academic license - for non-commercial use only\n",
      "λ=50.0\t MSE=0.3718550570800111\n",
      "Academic license - for non-commercial use only\n",
      "λ=60.0\t MSE=0.3834474851624372\n",
      "Academic license - for non-commercial use only\n",
      "λ=65.0\t MSE=0.3892277407998942\n",
      "Academic license - for non-commercial use only\n",
      "λ=70.0\t MSE=0.3949702943354228\n",
      "Academic license - for non-commercial use only\n",
      "λ=100.0\t MSE=0.4280532487359127\n",
      "Academic license - for non-commercial use only\n",
      "λ=500.0\t MSE=0.6730933633059385\n",
      "Academic license - for non-commercial use only\n",
      "λ=1000.0\t MSE=0.8006251449116313\n",
      "Best λ_RLS = 5.0\n",
      "Academic license - for non-commercial use only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.0874847635742329, 0.11584669107976685, -0.04320872279280865, 0.11899830175790778, -0.19000516655162503, 0.26686549239629803, 0.006943883753696587, -0.30021961115213497, 0.2578951074213603, -0.1619402439619094, -0.20852863268689673, 0.0763891540178019, -0.43795154700687033], 91.30975972428882)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train_RLS, Y_train_RLS), (X_val_RLS, Y_val_RLS) = IAI.split_data(\n",
    "    :classification, convert(DataFrame, X), Y, train_proportion=0.50, seed=7\n",
    ")\n",
    "(X_train_RLS, X_val_RLS) = (convert(Matrix, X_train_RLS), convert(Matrix, X_val_RLS))\n",
    "println(\"Obtained 70/30 train/val random split for RLS\")\n",
    "best_λ_RLS = 0\n",
    "best_MSE_RLS = 1000000\n",
    "for λ_RLS in [0, 0.01, 0.1, 0.5, 1, 5, 10, 20, 30, 40, 50, 60, 65, 70, 100, 500, 1000]\n",
    "    w_opt_RLS, obj_opt_RLS = regularized_least_squares(X_train_RLS, Y_train_RLS, λ_RLS)\n",
    "    MSE_RLS = calculate_MSE(X_val_RLS, Y_val_RLS, w_opt_RLS)\n",
    "    println(\"λ=\", λ_RLS, \"\\t MSE=\", MSE_RLS)\n",
    "    if MSE_RLS < best_MSE_RLS\n",
    "        best_MSE_RLS = MSE_RLS\n",
    "        best_λ_RLS = λ_RLS\n",
    "    end\n",
    "end\n",
    "println(\"Best λ_RLS = \", best_λ_RLS)\n",
    "w_opt_RLS, obj_opt_RLS = regularized_least_squares(\n",
    "        vcat(X_train_RLS, X_val_RLS), \n",
    "        vcat(Y_train_RLS, Y_val_RLS), \n",
    "        best_λ_RLS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best Stable Regression - Optimal Train/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T22:32:20.109000-05:00",
     "start_time": "2019-12-04T03:32:19.594Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n",
      "λ=0.0\t MSE=0.018811690494316226\n",
      "Academic license - for non-commercial use only\n",
      "λ=0.01\t MSE=0.018811690492093015\n",
      "Academic license - for non-commercial use only\n",
      "λ=0.1\t MSE=0.018811690487779583\n",
      "Academic license - for non-commercial use only\n",
      "λ=0.2\t MSE=0.018811690488389415\n",
      "Academic license - for non-commercial use only\n",
      "λ=1.0\t MSE=0.019116407403981545\n",
      "Academic license - for non-commercial use only\n",
      "λ=10.0\t MSE=0.019330328131172348\n",
      "Academic license - for non-commercial use only\n",
      "λ=20.0\t MSE=0.019245244215488788\n",
      "Academic license - for non-commercial use only\n",
      "λ=50.0\t MSE=0.020372933968512214\n",
      "Academic license - for non-commercial use only\n",
      "λ=100.0\t MSE=0.024665537846142786\n",
      "Best λ_SR = 0.1\n",
      "Academic license - for non-commercial use only\n",
      "Fitted Stable Regression with best possible λ_SR=0.1\n"
     ]
    }
   ],
   "source": [
    "k = floor(Int, 0.5*size(X, 1))\n",
    "best_λ_SR = 0\n",
    "best_MSE_SR = 1000000\n",
    "for λ_SR in [0, 0.01, 0.1, 0.2, 1, 10, 20, 50, 100]\n",
    "    w_opt_SR, u_opt_SR, θ_opt_SR, opt_obj_SR = stable_reg_l2(X, Y, λ_SR, k)\n",
    "    train_indices_SR, val_indices_SR = get_training_and_validation_indices(\n",
    "        X, Y, w_opt_SR, true, k\n",
    "    )\n",
    "    X_train_SR, Y_train_SR = X[train_indices_SR, :], Y[train_indices_SR]\n",
    "    X_val_SR, Y_val_SR = X[val_indices_SR, :], Y[val_indices_SR]\n",
    "    MSE_SR = calculate_MSE(X_val_SR, Y_val_SR, w_opt_SR)\n",
    "    println(\"λ=\", λ_SR, \"\\t MSE=\", MSE_SR)\n",
    "    if MSE_SR < best_MSE_SR\n",
    "        best_λ_SR = λ_SR\n",
    "        best_MSE_SR = MSE_SR\n",
    "    end\n",
    "end\n",
    "println(\"Best λ_SR = \", best_λ_SR)\n",
    "\n",
    "# Fitting Stable regression with best λ\n",
    "w_opt_SR, u_opt_SR, θ_opt_SR, opt_obj_SR = stable_reg_l2(X, Y, best_λ_SR, k)\n",
    "train_indices_SR, val_indices_SR = get_training_and_validation_indices(\n",
    "    X, Y, w_opt_SR, true, k\n",
    ")\n",
    "X_train_SR, Y_train_SR = X[train_indices_SR, :], Y[train_indices_SR]\n",
    "X_val_SR, Y_val_SR = X[val_indices_SR, :], Y[val_indices_SR]\n",
    "println(\"Fitted Stable Regression with best possible λ_SR=\", best_λ_SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T22:32:21.736000-05:00",
     "start_time": "2019-12-04T03:32:21.725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## The training scores are: ##########\n",
      "The MSE for the Regularized Least Squares is : 0.25741454132357167\n",
      "The MSE for the Stable Regression is : 0.5226158756772503\n",
      "########## The validation scores are: ##########\n",
      "The MSE for the Regularized Least Squares is : 0.2451690579836505\n",
      "The MSE for the Stable Regression is : 0.018811690487779583\n",
      "########## The test scores are: ##########\n",
      "The MSE for the Regularized Least Squares is : 0.3370607729413801\n",
      "The MSE for the Stable Regression is : 0.31936287842130967\n"
     ]
    }
   ],
   "source": [
    "println(\"########## The training scores are: ##########\")\n",
    "println(\"The MSE for the Regularized Least Squares is : \", \n",
    "    calculate_MSE(X_train_RLS, Y_train_RLS, w_opt_RLS))\n",
    "println(\"The MSE for the Stable Regression is : \", \n",
    "    calculate_MSE(X_train_SR, Y_train_SR, w_opt_SR))\n",
    "\n",
    "println(\"########## The validation scores are: ##########\")\n",
    "println(\"The MSE for the Regularized Least Squares is : \", \n",
    "    calculate_MSE(X_val_RLS, Y_val_RLS, w_opt_RLS))\n",
    "println(\"The MSE for the Stable Regression is : \", \n",
    "    calculate_MSE(X_val_SR, Y_val_SR, w_opt_SR))\n",
    "\n",
    "println(\"########## The test scores are: ##########\")\n",
    "println(\"The MSE for the Regularized Least Squares is : \", \n",
    "    calculate_MSE(X_test, Y_test, w_opt_RLS))\n",
    "println(\"The MSE for the Stable Regression is : \", \n",
    "    calculate_MSE(X_test, Y_test, w_opt_SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best EVaRegression $\\ell_2$ with random warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T13:17:52.358000-05:00",
     "start_time": "2019-12-03T17:59:23.466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λ=0.0\t c_s_EVaR=0.0001\t c_w_EVaR=0.0001\t MSE=0.011353493879241089\n",
      "λ=0.01\t c_s_EVaR=0.0001\t c_w_EVaR=0.0001\t MSE=0.011215496590247703\n",
      "λ=0.1\t c_s_EVaR=0.0001\t c_w_EVaR=0.0001\t MSE=0.010552636038916046\n",
      "λ=0.2\t c_s_EVaR=0.0001\t c_w_EVaR=0.0001\t MSE=0.010327368309117289\n",
      "λ=0.2\t c_s_EVaR=0.01\t c_w_EVaR=0.01\t MSE=0.010319655031776632\n",
      "λ=1.0\t c_s_EVaR=0.0001\t c_w_EVaR=0.0001\t MSE=0.008290100137572016\n",
      "λ=1.0\t c_s_EVaR=0.001\t c_w_EVaR=0.0001\t MSE=0.00821687797294475\n",
      "Best λ_EVaR = 1.0\t c_s_EVaR=0.001\t c_w_EVaR=0.0001\n",
      "Fitted EVaRegression ℓ_2 with best possible λ_EVaR=1.0  c_s_EVaR=0.001  c_w_EVaR=0.0001\n"
     ]
    }
   ],
   "source": [
    "n, p = size(X);   k = floor(Int, 0.7*n);   α = k/n;   ε=0.001\n",
    "# Initial values, we use RLS weights as warm start\n",
    "w_0 = ones(p)./100\n",
    "s_0 = 0.9\n",
    "\n",
    "\n",
    "best_λ_EVaR = 0\n",
    "best_c_s_EVaR = 0\n",
    "best_c_w_EVaR = 0\n",
    "best_MSE_EVaR = 1000000\n",
    "for λ_EVaR in [0, 0.01, 0.1, 0.2, 1, 10, 20, 50]\n",
    "    for c_s_EVaR in [0.0001, 0.001, 0.01, 0.1]\n",
    "        for c_w_EVaR in [0.0001, 0.001, 0.01, 0.1]\n",
    "            list_f_opt, s_opt, w_opt_EVaR = gradient_descent_EVaR_ℓ2(X,Y,s_0,w_0,α,λ_EVaR,c_s_EVaR,c_w_EVaR,ε)\n",
    "            train_indices_EVaR, val_indices_EVaR = get_training_and_validation_indices(\n",
    "                X, Y, w_opt_EVaR, true, k\n",
    "            )\n",
    "            X_train_EVaR, Y_train_EVaR = X[train_indices_EVaR, :], Y[train_indices_EVaR]\n",
    "            X_val_EVaR, Y_val_EVaR = X[val_indices_EVaR, :], Y[val_indices_EVaR]\n",
    "            MSE_EVaR = calculate_MSE(X_val_EVaR, Y_val_EVaR, w_opt_EVaR)\n",
    "            if MSE_EVaR < best_MSE_EVaR\n",
    "                best_λ_EVaR = λ_EVaR\n",
    "                best_c_s_EVaR = c_s_EVaR\n",
    "                best_c_w_EVaR = c_w_EVaR\n",
    "                best_MSE_EVaR = MSE_EVaR\n",
    "                println(\"λ=\", λ_EVaR, \"\\t c_s_EVaR=\", c_s_EVaR, \"\\t c_w_EVaR=\", c_w_EVaR, \"\\t MSE=\", MSE_EVaR)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "println(\"Best λ_EVaR = \", best_λ_EVaR, \"\\t c_s_EVaR=\", best_c_s_EVaR, \"\\t c_w_EVaR=\", best_c_w_EVaR)\n",
    "\n",
    "# Fitting Stable regression with best λ\n",
    "list_f_opt, s_opt, w_opt_EVaR = gradient_descent_EVaR_ℓ2(\n",
    "    X, Y, s_0, w_0, α, best_λ_EVaR, best_c_s_EVaR, best_c_w_EVaR, ε\n",
    ")\n",
    "train_indices_EVaR, val_indices_EVaR = get_training_and_validation_indices(\n",
    "    X, Y, w_opt_EVaR, true, k\n",
    ")\n",
    "X_train_EVaR, Y_train_EVaR = X[train_indices_EVaR, :], Y[train_indices_EVaR]\n",
    "X_val_EVaR, Y_val_EVaR = X[val_indices_EVaR, :], Y[val_indices_EVaR]\n",
    "println(\"Fitted EVaRegression ℓ_2 with best possible λ_EVaR=\", best_λ_EVaR, \n",
    "    \"  c_s_EVaR=\", best_c_s_EVaR, \"  c_w_EVaR=\", best_c_w_EVaR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best EVaRegression  $ℓ_2$  with RLS weights warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T13:34:17.357000-05:00",
     "start_time": "2019-12-03T17:59:27.214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λ=0.0\t c_s_EVaR_with_warmstart=0.0001\t c_w_EVaR_with_warmstart=0.0001\t MSE=0.01197949356474254\n",
      "λ=0.0\t c_s_EVaR_with_warmstart=0.001\t c_w_EVaR_with_warmstart=0.001\t MSE=0.011979471106725878\n",
      "λ=0.0\t c_s_EVaR_with_warmstart=0.01\t c_w_EVaR_with_warmstart=0.01\t MSE=0.011978110786313476\n",
      "λ=0.01\t c_s_EVaR_with_warmstart=0.0001\t c_w_EVaR_with_warmstart=0.0001\t MSE=0.011813477546025143\n",
      "λ=0.01\t c_s_EVaR_with_warmstart=0.001\t c_w_EVaR_with_warmstart=0.001\t MSE=0.011813233762080884\n",
      "λ=0.01\t c_s_EVaR_with_warmstart=0.01\t c_w_EVaR_with_warmstart=0.01\t MSE=0.011809258716127143\n",
      "λ=0.1\t c_s_EVaR_with_warmstart=0.0001\t c_w_EVaR_with_warmstart=0.0001\t MSE=0.010714589149813844\n",
      "λ=0.1\t c_s_EVaR_with_warmstart=0.001\t c_w_EVaR_with_warmstart=0.0001\t MSE=0.010680302288356704\n",
      "λ=0.1\t c_s_EVaR_with_warmstart=0.01\t c_w_EVaR_with_warmstart=0.001\t MSE=0.01068018639445509\n",
      "λ=0.1\t c_s_EVaR_with_warmstart=0.1\t c_w_EVaR_with_warmstart=0.01\t MSE=0.010676869821079621\n",
      "λ=0.2\t c_s_EVaR_with_warmstart=0.0001\t c_w_EVaR_with_warmstart=0.0001\t MSE=0.010273914739200835\n",
      "λ=0.2\t c_s_EVaR_with_warmstart=0.001\t c_w_EVaR_with_warmstart=0.0001\t MSE=0.01018538447683538\n",
      "λ=0.2\t c_s_EVaR_with_warmstart=0.01\t c_w_EVaR_with_warmstart=0.001\t MSE=0.010185345947690133\n",
      "λ=0.2\t c_s_EVaR_with_warmstart=0.1\t c_w_EVaR_with_warmstart=0.01\t MSE=0.010183948214762442\n",
      "λ=1.0\t c_s_EVaR_with_warmstart=0.0001\t c_w_EVaR_with_warmstart=0.0001\t MSE=0.008302662057854293\n",
      "λ=1.0\t c_s_EVaR_with_warmstart=0.001\t c_w_EVaR_with_warmstart=0.0001\t MSE=0.008283907276002722\n",
      "λ=1.0\t c_s_EVaR_with_warmstart=0.001\t c_w_EVaR_with_warmstart=0.001\t MSE=0.008283335969108385\n",
      "λ=1.0\t c_s_EVaR_with_warmstart=0.01\t c_w_EVaR_with_warmstart=0.0001\t MSE=0.008280479675077234\n",
      "λ=1.0\t c_s_EVaR_with_warmstart=0.1\t c_w_EVaR_with_warmstart=0.0001\t MSE=0.008280372766621486\n",
      "Best λ_EVaR_with_warmstart = 1.0\t c_s_EVaR_with_warmstart=0.1\t c_w_EVaR_with_warmstart=0.0001\n",
      "Fitted EVaRegression ℓ_2 with best possible λ_EVaR_with_warmstart=1.0  c_s_EVaR_with_warmstart=0.1  c_w_EVaR_with_warmstart=0.0001\n"
     ]
    }
   ],
   "source": [
    "n, p = size(X);   k = floor(Int, 0.7*n);   α = k/n;   ε=0.001\n",
    "# Initial values, we use RLS weights as warm start\n",
    "w_0 = w_opt_RLS\n",
    "s_0 = 0.9\n",
    "\n",
    "\n",
    "best_λ_EVaR_with_warmstart = 0\n",
    "best_c_s_EVaR_with_warmstart = 0\n",
    "best_c_w_EVaR_with_warmstart = 0\n",
    "best_MSE_EVaR_with_warmstart = 1000000\n",
    "for λ_EVaR_with_warmstart in [0, 0.01, 0.1, 0.2, 1, 10, 20, 50]\n",
    "    for c_s_EVaR_with_warmstart in [0.0001, 0.001, 0.01, 0.1]\n",
    "        for c_w_EVaR_with_warmstart in [0.0001, 0.001, 0.01, 0.1]\n",
    "            list_f_opt, s_opt, w_opt_EVaR_with_warmstart = gradient_descent_EVaR_ℓ2(\n",
    "                X,Y,s_0,w_0,α,λ_EVaR_with_warmstart,c_s_EVaR_with_warmstart,c_w_EVaR_with_warmstart,ε\n",
    "            )\n",
    "            train_indices_EVaR_with_warmstart, val_indices_EVaR_with_warmstart = get_training_and_validation_indices(\n",
    "                X, Y, w_opt_EVaR_with_warmstart, true, k\n",
    "            )\n",
    "            X_train_EVaR_with_warmstart, Y_train_EVaR_with_warmstart = X[train_indices_EVaR_with_warmstart, :], Y[train_indices_EVaR_with_warmstart]\n",
    "            X_val_EVaR_with_warmstart, Y_val_EVaR_with_warmstart = X[val_indices_EVaR_with_warmstart, :], Y[val_indices_EVaR_with_warmstart]\n",
    "            MSE_EVaR_with_warmstart = calculate_MSE(X_val_EVaR_with_warmstart, Y_val_EVaR_with_warmstart, w_opt_EVaR_with_warmstart)\n",
    "            if MSE_EVaR_with_warmstart < best_MSE_EVaR_with_warmstart\n",
    "                best_λ_EVaR_with_warmstart = λ_EVaR_with_warmstart\n",
    "                best_c_s_EVaR_with_warmstart = c_s_EVaR_with_warmstart\n",
    "                best_c_w_EVaR_with_warmstart = c_w_EVaR_with_warmstart\n",
    "                best_MSE_EVaR_with_warmstart = MSE_EVaR_with_warmstart\n",
    "                println(\"λ=\", λ_EVaR_with_warmstart, \"\\t c_s_EVaR_with_warmstart=\", \n",
    "                    c_s_EVaR_with_warmstart, \"\\t c_w_EVaR_with_warmstart=\", \n",
    "                    c_w_EVaR_with_warmstart, \"\\t MSE=\", MSE_EVaR_with_warmstart)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "println(\"Best λ_EVaR_with_warmstart = \", best_λ_EVaR_with_warmstart, \n",
    "    \"\\t c_s_EVaR_with_warmstart=\", best_c_s_EVaR_with_warmstart, \n",
    "    \"\\t c_w_EVaR_with_warmstart=\", best_c_w_EVaR_with_warmstart)\n",
    "\n",
    "# Fitting Stable regression with best λ\n",
    "list_f_opt, s_opt, w_opt_EVaR_with_warmstart = gradient_descent_EVaR_ℓ2(\n",
    "    X, Y, s_0, w_0, α, best_λ_EVaR_with_warmstart, \n",
    "    best_c_s_EVaR_with_warmstart, best_c_w_EVaR_with_warmstart, ε\n",
    ")\n",
    "train_indices_EVaR_with_warmstart, val_indices_EVaR_with_warmstart = get_training_and_validation_indices(\n",
    "    X, Y, w_opt_EVaR_with_warmstart, true, k\n",
    ")\n",
    "X_train_EVaR_with_warmstart, Y_train_EVaR_with_warmstart = X[train_indices_EVaR_with_warmstart, :], Y[train_indices_EVaR_with_warmstart]\n",
    "X_val_EVaR_with_warmstart, Y_val_EVaR_with_warmstart = X[val_indices_EVaR_with_warmstart, :], Y[val_indices_EVaR_with_warmstart]\n",
    "println(\"Fitted EVaRegression ℓ_2 with best possible λ_EVaR_with_warmstart=\", best_λ_EVaR_with_warmstart, \n",
    "    \"  c_s_EVaR_with_warmstart=\", best_c_s_EVaR_with_warmstart, \n",
    "    \"  c_w_EVaR_with_warmstart=\", best_c_w_EVaR_with_warmstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best EVaRegression $\\ell_1$ with random warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T14:00:33.589000-05:00",
     "start_time": "2019-12-03T17:59:28.300Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λ=0.0\t c_s_EVaR_ℓ1=0.0001\t c_w_EVaR_ℓ1=0.0001\t MSE=0.005524026983371302\n",
      "0.0    0.0001    0.001\n",
      "0.0    0.0001    0.01\n",
      "0.0    0.0001    0.1\n",
      "0.0    0.001    0.0001\n",
      "0.0    0.001    0.001\n",
      "0.0    0.001    0.01\n",
      "0.0    0.001    0.1\n",
      "0.0    0.01    0.0001\n",
      "0.0    0.01    0.001\n",
      "0.0    0.01    0.01\n",
      "0.0    0.01    0.1\n",
      "0.0    0.1    0.0001\n",
      "0.0    0.1    0.001\n",
      "0.0    0.1    0.01\n",
      "0.0    0.1    0.1\n",
      "0.01    0.0001    0.0001\n",
      "0.01    0.0001    0.001\n",
      "0.01    0.0001    0.01\n",
      "0.01    0.0001    0.1\n",
      "0.01    0.001    0.0001\n",
      "0.01    0.001    0.001\n",
      "0.01    0.001    0.01\n",
      "0.01    0.001    0.1\n",
      "0.01    0.01    0.0001\n",
      "0.01    0.01    0.001\n",
      "0.01    0.01    0.01\n",
      "0.01    0.01    0.1\n",
      "0.01    0.1    0.0001\n",
      "0.01    0.1    0.001\n",
      "0.01    0.1    0.01\n",
      "0.01    0.1    0.1\n",
      "0.1    0.0001    0.0001\n",
      "0.1    0.0001    0.001\n",
      "0.1    0.0001    0.01\n",
      "0.1    0.0001    0.1\n",
      "0.1    0.001    0.0001\n",
      "0.1    0.001    0.001\n",
      "0.1    0.001    0.01\n",
      "0.1    0.001    0.1\n",
      "0.1    0.01    0.0001\n",
      "0.1    0.01    0.001\n",
      "0.1    0.01    0.01\n",
      "0.1    0.01    0.1\n",
      "0.1    0.1    0.0001\n",
      "0.1    0.1    0.001\n",
      "0.1    0.1    0.01\n",
      "0.1    0.1    0.1\n",
      "0.2    0.0001    0.0001\n",
      "0.2    0.0001    0.001\n",
      "0.2    0.0001    0.01\n",
      "0.2    0.0001    0.1\n",
      "0.2    0.001    0.0001\n",
      "0.2    0.001    0.001\n",
      "0.2    0.001    0.01\n",
      "0.2    0.001    0.1\n",
      "0.2    0.01    0.0001\n",
      "0.2    0.01    0.001\n",
      "0.2    0.01    0.01\n",
      "0.2    0.01    0.1\n",
      "0.2    0.1    0.0001\n",
      "0.2    0.1    0.001\n",
      "0.2    0.1    0.01\n",
      "0.2    0.1    0.1\n",
      "1.0    0.0001    0.0001\n",
      "1.0    0.0001    0.001\n",
      "1.0    0.0001    0.01\n",
      "1.0    0.0001    0.1\n",
      "1.0    0.001    0.0001\n",
      "1.0    0.001    0.001\n",
      "1.0    0.001    0.01\n",
      "1.0    0.001    0.1\n",
      "1.0    0.01    0.0001\n",
      "1.0    0.01    0.001\n",
      "1.0    0.01    0.01\n",
      "1.0    0.01    0.1\n",
      "1.0    0.1    0.0001\n",
      "1.0    0.1    0.001\n",
      "1.0    0.1    0.01\n",
      "1.0    0.1    0.1\n",
      "10.0    0.0001    0.0001\n",
      "10.0    0.0001    0.001\n",
      "10.0    0.0001    0.01\n",
      "10.0    0.0001    0.1\n",
      "10.0    0.001    0.0001\n",
      "10.0    0.001    0.001\n",
      "10.0    0.001    0.01\n",
      "10.0    0.001    0.1\n",
      "10.0    0.01    0.0001\n",
      "10.0    0.01    0.001\n",
      "10.0    0.01    0.01\n",
      "10.0    0.01    0.1\n",
      "10.0    0.1    0.0001\n",
      "10.0    0.1    0.001\n",
      "10.0    0.1    0.01\n",
      "10.0    0.1    0.1\n",
      "20.0    0.0001    0.0001\n",
      "20.0    0.0001    0.001\n",
      "20.0    0.0001    0.01\n",
      "20.0    0.0001    0.1\n",
      "20.0    0.001    0.0001\n",
      "20.0    0.001    0.001\n",
      "20.0    0.001    0.01\n",
      "20.0    0.001    0.1\n",
      "20.0    0.01    0.0001\n",
      "20.0    0.01    0.001\n",
      "20.0    0.01    0.01\n",
      "20.0    0.01    0.1\n",
      "20.0    0.1    0.0001\n",
      "20.0    0.1    0.001\n",
      "20.0    0.1    0.01\n",
      "20.0    0.1    0.1\n",
      "50.0    0.0001    0.0001\n",
      "50.0    0.0001    0.001\n",
      "50.0    0.0001    0.01\n",
      "50.0    0.0001    0.1\n",
      "50.0    0.001    0.0001\n",
      "50.0    0.001    0.001\n",
      "50.0    0.001    0.01\n",
      "50.0    0.001    0.1\n",
      "50.0    0.01    0.0001\n",
      "50.0    0.01    0.001\n",
      "50.0    0.01    0.01\n",
      "50.0    0.01    0.1\n",
      "50.0    0.1    0.0001\n",
      "50.0    0.1    0.001\n",
      "50.0    0.1    0.01\n",
      "50.0    0.1    0.1\n",
      "Best λ_EVaR_ℓ1 = 0.0\t c_s_EVaR_ℓ1=0.0001\t c_w_EVaR_ℓ1=0.0001\n"
     ]
    }
   ],
   "source": [
    "n, p = size(X);   k = floor(Int, 0.7*n);   α = k/n;   ε=0.001\n",
    "# Initial values, we use RLS weights as warm start\n",
    "w_0 = ones(p)./100\n",
    "s_0 = 0.9\n",
    "\n",
    "\n",
    "best_λ_EVaR_ℓ1 = 0\n",
    "best_c_s_EVaR_ℓ1 = 0\n",
    "best_c_w_EVaR_ℓ1 = 0\n",
    "best_MSE_EVaR_ℓ1 = 1000000\n",
    "for λ_EVaR_ℓ1 in [0, 0.01, 0.1, 0.2, 1, 10, 20, 50]\n",
    "    for c_s_EVaR_ℓ1 in [0.0001, 0.001, 0.01, 0.1]\n",
    "        for c_w_EVaR_ℓ1 in [0.0001, 0.001, 0.01, 0.1]\n",
    "            list_f_opt, s_opt, w_opt_EVaR_ℓ1 = gradient_descent_EVaR_ℓ1(X,Y,s_0,w_0,α,λ_EVaR_ℓ1,c_s_EVaR_ℓ1,c_w_EVaR_ℓ1,ε)\n",
    "            train_indices_EVaR_ℓ1, val_indices_EVaR_ℓ1 = get_training_and_validation_indices(\n",
    "                X, Y, w_opt_EVaR_ℓ1, true, k\n",
    "            )\n",
    "            X_train_EVaR_ℓ1, Y_train_EVaR_ℓ1 = X[train_indices_EVaR_ℓ1, :], Y[train_indices_EVaR_ℓ1]\n",
    "            X_val_EVaR_ℓ1, Y_val_EVaR_ℓ1 = X[val_indices_EVaR_ℓ1, :], Y[val_indices_EVaR_ℓ1]\n",
    "            MSE_EVaR_ℓ1 = calculate_MSE(X_val_EVaR_ℓ1, Y_val_EVaR_ℓ1, w_opt_EVaR_ℓ1)\n",
    "            if MSE_EVaR_ℓ1 < best_MSE_EVaR_ℓ1\n",
    "                best_λ_EVaR_ℓ1 = λ_EVaR_ℓ1\n",
    "                best_c_s_EVaR_ℓ1 = c_s_EVaR_ℓ1\n",
    "                best_c_w_EVaR_ℓ1 = c_w_EVaR_ℓ1\n",
    "                best_MSE_EVaR_ℓ1 = MSE_EVaR_ℓ1\n",
    "                println(\"λ=\", λ_EVaR_ℓ1, \"\\t c_s_EVaR_ℓ1=\", c_s_EVaR_ℓ1, \"\\t c_w_EVaR_ℓ1=\", c_w_EVaR_ℓ1, \"\\t MSE=\", MSE_EVaR_ℓ1)\n",
    "            else\n",
    "                println(λ_EVaR_ℓ1, \"    \",c_s_EVaR_ℓ1, \"    \", c_w_EVaR_ℓ1)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "println(\"Best λ_EVaR_ℓ1 = \", best_λ_EVaR_ℓ1, \"\\t c_s_EVaR_ℓ1=\", best_c_s_EVaR_ℓ1, \"\\t c_w_EVaR_ℓ1=\", best_c_w_EVaR_ℓ1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T14:01:08.042000-05:00",
     "start_time": "2019-12-03T17:59:29.209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted EVaR_ℓ1egression ℓ_1 with best possible λ_EVaR_ℓ1=0.0  c_s_EVaR_ℓ1=0.0001  c_w_EVaR_ℓ1=0.0001\n"
     ]
    }
   ],
   "source": [
    "# Fitting Stable regression with best λ\n",
    "list_f_opt, s_opt, w_opt_EVaR_ℓ1 = gradient_descent_EVaR_ℓ1(\n",
    "    X, Y, s_0, w_0, α, best_λ_EVaR_ℓ1, best_c_s_EVaR_ℓ1, best_c_w_EVaR_ℓ1, ε\n",
    ")\n",
    "train_indices_EVaR_ℓ1, val_indices_EVaR_ℓ1 = get_training_and_validation_indices(\n",
    "    X, Y, w_opt_EVaR_ℓ1, true, k\n",
    ")\n",
    "X_train_EVaR_ℓ1, Y_train_EVaR_ℓ1 = X[train_indices_EVaR_ℓ1, :], Y[train_indices_EVaR_ℓ1]\n",
    "X_val_EVaR_ℓ1, Y_val_EVaR_ℓ1 = X[val_indices_EVaR_ℓ1, :], Y[val_indices_EVaR_ℓ1]\n",
    "println(\"Fitted EVaR_ℓ1egression ℓ_1 with best possible λ_EVaR_ℓ1=\", best_λ_EVaR_ℓ1, \n",
    "    \"  c_s_EVaR_ℓ1=\", best_c_s_EVaR_ℓ1, \"  c_w_EVaR_ℓ1=\", best_c_w_EVaR_ℓ1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best EVaRegression  $ℓ_1$  with RLS weights warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T14:24:38.013000-05:00",
     "start_time": "2019-12-03T17:59:32.015Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λ=0.0\t c_s_EVaR_ℓ1_with_warmstart=0.0001\t c_w_EVaR_ℓ1_with_warmstart=0.0001\t MSE=0.005756717047838035\n",
      "λ=0.0\t c_s_EVaR_ℓ1_with_warmstart=0.0001\t c_w_EVaR_ℓ1_with_warmstart=0.001\t MSE=0.005580877545561708\n",
      "λ=0.0\t c_s_EVaR_ℓ1_with_warmstart=0.0001\t c_w_EVaR_ℓ1_with_warmstart=0.01\t MSE=0.005553410801608024\n",
      "0.0    0.0001    0.1\n",
      "0.0    0.001    0.0001\n",
      "0.0    0.001    0.001\n",
      "0.0    0.001    0.01\n",
      "0.0    0.001    0.1\n",
      "0.0    0.01    0.0001\n",
      "0.0    0.01    0.001\n",
      "0.0    0.01    0.01\n",
      "0.0    0.01    0.1\n",
      "0.0    0.1    0.0001\n",
      "0.0    0.1    0.001\n",
      "0.0    0.1    0.01\n",
      "0.0    0.1    0.1\n",
      "0.01    0.0001    0.0001\n",
      "0.01    0.0001    0.001\n",
      "0.01    0.0001    0.01\n",
      "0.01    0.0001    0.1\n",
      "0.01    0.001    0.0001\n",
      "0.01    0.001    0.001\n",
      "0.01    0.001    0.01\n",
      "0.01    0.001    0.1\n",
      "0.01    0.01    0.0001\n",
      "0.01    0.01    0.001\n",
      "0.01    0.01    0.01\n",
      "0.01    0.01    0.1\n",
      "0.01    0.1    0.0001\n",
      "0.01    0.1    0.001\n",
      "0.01    0.1    0.01\n",
      "0.01    0.1    0.1\n",
      "0.1    0.0001    0.0001\n",
      "0.1    0.0001    0.001\n",
      "0.1    0.0001    0.01\n",
      "0.1    0.0001    0.1\n",
      "0.1    0.001    0.0001\n",
      "0.1    0.001    0.001\n",
      "0.1    0.001    0.01\n",
      "0.1    0.001    0.1\n",
      "0.1    0.01    0.0001\n",
      "0.1    0.01    0.001\n",
      "0.1    0.01    0.01\n",
      "0.1    0.01    0.1\n",
      "0.1    0.1    0.0001\n",
      "0.1    0.1    0.001\n",
      "0.1    0.1    0.01\n",
      "0.1    0.1    0.1\n",
      "0.2    0.0001    0.0001\n",
      "0.2    0.0001    0.001\n",
      "0.2    0.0001    0.01\n",
      "0.2    0.0001    0.1\n",
      "0.2    0.001    0.0001\n",
      "0.2    0.001    0.001\n",
      "0.2    0.001    0.01\n",
      "0.2    0.001    0.1\n",
      "0.2    0.01    0.0001\n",
      "0.2    0.01    0.001\n",
      "0.2    0.01    0.01\n",
      "0.2    0.01    0.1\n",
      "0.2    0.1    0.0001\n",
      "0.2    0.1    0.001\n",
      "0.2    0.1    0.01\n",
      "0.2    0.1    0.1\n",
      "1.0    0.0001    0.0001\n",
      "1.0    0.0001    0.001\n",
      "1.0    0.0001    0.01\n",
      "1.0    0.0001    0.1\n",
      "1.0    0.001    0.0001\n",
      "1.0    0.001    0.001\n",
      "1.0    0.001    0.01\n",
      "1.0    0.001    0.1\n",
      "1.0    0.01    0.0001\n",
      "1.0    0.01    0.001\n",
      "1.0    0.01    0.01\n",
      "1.0    0.01    0.1\n",
      "1.0    0.1    0.0001\n",
      "1.0    0.1    0.001\n",
      "1.0    0.1    0.01\n",
      "1.0    0.1    0.1\n",
      "10.0    0.0001    0.0001\n",
      "10.0    0.0001    0.001\n",
      "10.0    0.0001    0.01\n",
      "10.0    0.0001    0.1\n",
      "10.0    0.001    0.0001\n",
      "10.0    0.001    0.001\n",
      "10.0    0.001    0.01\n",
      "10.0    0.001    0.1\n",
      "10.0    0.01    0.0001\n",
      "10.0    0.01    0.001\n",
      "10.0    0.01    0.01\n",
      "10.0    0.01    0.1\n",
      "10.0    0.1    0.0001\n",
      "10.0    0.1    0.001\n",
      "10.0    0.1    0.01\n",
      "10.0    0.1    0.1\n",
      "20.0    0.0001    0.0001\n",
      "20.0    0.0001    0.001\n",
      "20.0    0.0001    0.01\n",
      "20.0    0.0001    0.1\n",
      "20.0    0.001    0.0001\n",
      "20.0    0.001    0.001\n",
      "20.0    0.001    0.01\n",
      "20.0    0.001    0.1\n",
      "20.0    0.01    0.0001\n",
      "20.0    0.01    0.001\n",
      "20.0    0.01    0.01\n",
      "20.0    0.01    0.1\n",
      "20.0    0.1    0.0001\n",
      "20.0    0.1    0.001\n",
      "20.0    0.1    0.01\n",
      "20.0    0.1    0.1\n",
      "50.0    0.0001    0.0001\n",
      "50.0    0.0001    0.001\n",
      "50.0    0.0001    0.01\n",
      "50.0    0.0001    0.1\n",
      "50.0    0.001    0.0001\n",
      "50.0    0.001    0.001\n",
      "50.0    0.001    0.01\n",
      "50.0    0.001    0.1\n",
      "50.0    0.01    0.0001\n",
      "50.0    0.01    0.001\n",
      "50.0    0.01    0.01\n",
      "50.0    0.01    0.1\n",
      "50.0    0.1    0.0001\n",
      "50.0    0.1    0.001\n",
      "50.0    0.1    0.01\n",
      "50.0    0.1    0.1\n",
      "Best λ_EVaR_ℓ1_with_warmstart = 0.0\t c_s_EVaR_ℓ1_with_warmstart=0.0001\t c_w_EVaR_ℓ1_with_warmstart=0.01\n"
     ]
    }
   ],
   "source": [
    "n, p = size(X);   k = floor(Int, 0.7*n);   α = k/n;   ε=0.001\n",
    "# Initial values, we use RLS weights as warm start\n",
    "w_0 = w_opt_RLS\n",
    "s_0 = 0.9\n",
    "\n",
    "\n",
    "best_λ_EVaR_ℓ1_with_warmstart = 0\n",
    "best_c_s_EVaR_ℓ1_with_warmstart = 0\n",
    "best_c_w_EVaR_ℓ1_with_warmstart = 0\n",
    "best_MSE_EVaR_ℓ1_with_warmstart = 1000000\n",
    "for λ_EVaR_ℓ1_with_warmstart in [0, 0.01, 0.1, 0.2, 1, 10, 20, 50]\n",
    "    for c_s_EVaR_ℓ1_with_warmstart in [0.0001, 0.001, 0.01, 0.1]\n",
    "        for c_w_EVaR_ℓ1_with_warmstart in [0.0001, 0.001, 0.01, 0.1]\n",
    "            list_f_opt, s_opt, w_opt_EVaR_ℓ1_with_warmstart = gradient_descent_EVaR_ℓ1(\n",
    "                X,Y,s_0,w_0,α,λ_EVaR_ℓ1_with_warmstart,c_s_EVaR_ℓ1_with_warmstart,c_w_EVaR_ℓ1_with_warmstart,ε\n",
    "            )\n",
    "            train_indices_EVaR_ℓ1_with_warmstart, val_indices_EVaR_ℓ1_with_warmstart = get_training_and_validation_indices(\n",
    "                X, Y, w_opt_EVaR_ℓ1_with_warmstart, true, k\n",
    "            )\n",
    "            X_train_EVaR_ℓ1_with_warmstart, Y_train_EVaR_ℓ1_with_warmstart = X[train_indices_EVaR_ℓ1_with_warmstart, :], Y[train_indices_EVaR_ℓ1_with_warmstart]\n",
    "            X_val_EVaR_ℓ1_with_warmstart, Y_val_EVaR_ℓ1_with_warmstart = X[val_indices_EVaR_ℓ1_with_warmstart, :], Y[val_indices_EVaR_ℓ1_with_warmstart]\n",
    "            MSE_EVaR_ℓ1_with_warmstart = calculate_MSE(X_val_EVaR_ℓ1_with_warmstart, Y_val_EVaR_ℓ1_with_warmstart, w_opt_EVaR_ℓ1_with_warmstart)\n",
    "            if MSE_EVaR_ℓ1_with_warmstart < best_MSE_EVaR_ℓ1_with_warmstart\n",
    "                best_λ_EVaR_ℓ1_with_warmstart = λ_EVaR_ℓ1_with_warmstart\n",
    "                best_c_s_EVaR_ℓ1_with_warmstart = c_s_EVaR_ℓ1_with_warmstart\n",
    "                best_c_w_EVaR_ℓ1_with_warmstart = c_w_EVaR_ℓ1_with_warmstart\n",
    "                best_MSE_EVaR_ℓ1_with_warmstart = MSE_EVaR_ℓ1_with_warmstart\n",
    "                println(\"λ=\", λ_EVaR_ℓ1_with_warmstart, \"\\t c_s_EVaR_ℓ1_with_warmstart=\", \n",
    "                    c_s_EVaR_ℓ1_with_warmstart, \"\\t c_w_EVaR_ℓ1_with_warmstart=\", \n",
    "                    c_w_EVaR_ℓ1_with_warmstart, \"\\t MSE=\", MSE_EVaR_ℓ1_with_warmstart)\n",
    "            else\n",
    "                println(λ_EVaR_ℓ1_with_warmstart, \"    \", \n",
    "                    c_s_EVaR_ℓ1_with_warmstart, \"    \", \n",
    "                    c_w_EVaR_ℓ1_with_warmstart)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "println(\"Best λ_EVaR_ℓ1_with_warmstart = \", best_λ_EVaR_ℓ1_with_warmstart, \n",
    "    \"\\t c_s_EVaR_ℓ1_with_warmstart=\", best_c_s_EVaR_ℓ1_with_warmstart, \n",
    "    \"\\t c_w_EVaR_ℓ1_with_warmstart=\", best_c_w_EVaR_ℓ1_with_warmstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T14:25:05.209000-05:00",
     "start_time": "2019-12-03T17:59:33.890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted EVaR_ℓ1egression ℓ_1 with best possible λ_EVaR_ℓ1_with_warmstart=0.0  c_s_EVaR_ℓ1_with_warmstart=0.0001  c_w_EVaR_ℓ1_with_warmstart=0.01\n"
     ]
    }
   ],
   "source": [
    "# Fitting Stable regression with best λ\n",
    "list_f_opt, s_opt, w_opt_EVaR_ℓ1_with_warmstart = gradient_descent_EVaR_ℓ1(\n",
    "    X, Y, s_0, w_0, α, best_λ_EVaR_ℓ1_with_warmstart, \n",
    "    best_c_s_EVaR_ℓ1_with_warmstart, best_c_w_EVaR_ℓ1_with_warmstart, ε\n",
    ")\n",
    "train_indices_EVaR_ℓ1_with_warmstart, val_indices_EVaR_ℓ1_with_warmstart = get_training_and_validation_indices(\n",
    "    X, Y, w_opt_EVaR_ℓ1_with_warmstart, true, k\n",
    ")\n",
    "X_train_EVaR_ℓ1_with_warmstart, Y_train_EVaR_ℓ1_with_warmstart = X[train_indices_EVaR_ℓ1_with_warmstart, :], Y[train_indices_EVaR_ℓ1_with_warmstart]\n",
    "X_val_EVaR_ℓ1_with_warmstart, Y_val_EVaR_ℓ1_with_warmstart = X[val_indices_EVaR_ℓ1_with_warmstart, :], Y[val_indices_EVaR_ℓ1_with_warmstart]\n",
    "println(\"Fitted EVaR_ℓ1egression ℓ_1 with best possible λ_EVaR_ℓ1_with_warmstart=\", best_λ_EVaR_ℓ1_with_warmstart, \n",
    "    \"  c_s_EVaR_ℓ1_with_warmstart=\", best_c_s_EVaR_ℓ1_with_warmstart, \n",
    "    \"  c_w_EVaR_ℓ1_with_warmstart=\", best_c_w_EVaR_ℓ1_with_warmstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Showcase train/validation/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T14:25:05.223000-05:00",
     "start_time": "2019-12-03T17:59:38.866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## The training scores are: ##########\n",
      "The MSE for the Regularized Least Squares is : 0.24939957072262187\n",
      "The MSE for the Stable Regression is : 0.3891561632813787\n",
      "The MSE for the EVaR Regression is for ε = 0.001 : 0.44587952890294147\n",
      "The MSE for the EVaR Regression with RLS warm start is for ε = 0.001 : 0.4433744426143271\n",
      "The MSE for the EVaR_ℓ1 Regression is for ε = 0.001 : 0.36965720683890785\n",
      "The MSE for the EVaR_ℓ1 Regression with RLS warm start is for ε = 0.001 : 0.3706927110481816\n"
     ]
    }
   ],
   "source": [
    "println(\"########## The training scores are: ##########\")\n",
    "println(\"The MSE for the Regularized Least Squares is : \", \n",
    "    calculate_MSE(X_train_RLS, Y_train_RLS, w_opt_RLS))\n",
    "println(\"The MSE for the Stable Regression is : \", \n",
    "    calculate_MSE(X_train_SR, Y_train_SR, w_opt_SR))\n",
    "println(\"The MSE for the EVaR Regression is for ε = 0.001 : \", \n",
    "    calculate_MSE(X_train_EVaR, Y_train_EVaR, w_opt_EVaR))\n",
    "println(\"The MSE for the EVaR Regression with RLS warm start is for ε = 0.001 : \", \n",
    "    calculate_MSE(X_train_EVaR_with_warmstart, Y_train_EVaR_with_warmstart, w_opt_EVaR_with_warmstart))\n",
    "println(\"The MSE for the EVaR_ℓ1 Regression is for ε = 0.001 : \", \n",
    "    calculate_MSE(X_train_EVaR_ℓ1, Y_train_EVaR_ℓ1, w_opt_EVaR_ℓ1))\n",
    "println(\"The MSE for the EVaR_ℓ1 Regression with RLS warm start is for ε = 0.001 : \", \n",
    "    calculate_MSE(X_train_EVaR_ℓ1_with_warmstart, Y_train_EVaR_ℓ1_with_warmstart, w_opt_EVaR_ℓ1_with_warmstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T14:25:05.244000-05:00",
     "start_time": "2019-12-03T17:59:39.545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## The validation scores are: ##########\n",
      "The MSE for the Regularized Least Squares is : 0.24958703550063438\n",
      "The MSE for the Stable Regression is : 0.0067152173017977455\n",
      "The MSE for the EVaR Regression is for ε = 0.001 : 0.00821687797294475\n",
      "The MSE for the EVaR Regression with RLS warm start is for ε = 0.001 : 0.008280372766621486\n",
      "The MSE for the EVaR_ℓ1 Regression is for ε = 0.001 : 0.005524026983371302\n",
      "The MSE for the EVaR_ℓ1 Regression with RLS warm start is for ε = 0.001 : 0.005553410801608024\n"
     ]
    }
   ],
   "source": [
    "println(\"########## The validation scores are: ##########\")\n",
    "println(\"The MSE for the Regularized Least Squares is : \", \n",
    "    calculate_MSE(X_val_RLS, Y_val_RLS, w_opt_RLS))\n",
    "println(\"The MSE for the Stable Regression is : \", \n",
    "    calculate_MSE(X_val_SR, Y_val_SR, w_opt_SR))\n",
    "println(\"The MSE for the EVaR Regression is for ε = 0.001 : \", \n",
    "    calculate_MSE(X_val_EVaR, Y_val_EVaR, w_opt_EVaR))\n",
    "println(\"The MSE for the EVaR Regression with RLS warm start is for ε = 0.001 : \", \n",
    "    calculate_MSE(X_val_EVaR_with_warmstart, Y_val_EVaR_with_warmstart, w_opt_EVaR_with_warmstart))\n",
    "println(\"The MSE for the EVaR_ℓ1 Regression is for ε = 0.001 : \", \n",
    "    calculate_MSE(X_val_EVaR_ℓ1, Y_val_EVaR_ℓ1, w_opt_EVaR_ℓ1))\n",
    "println(\"The MSE for the EVaR_ℓ1 Regression with RLS warm start is for ε = 0.001 : \", \n",
    "    calculate_MSE(X_val_EVaR_ℓ1_with_warmstart, Y_val_EVaR_ℓ1_with_warmstart, w_opt_EVaR_ℓ1_with_warmstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T14:25:05.259000-05:00",
     "start_time": "2019-12-03T17:59:40.097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## The test scores are: ##########\n",
      "The MSE for the Regularized Least Squares is : 0.336139105961579\n",
      "The MSE for the Stable Regression is : 0.32602997802296224\n",
      "The MSE for the EVaR Regression is for ε = 0.001 : 0.4473116642845203\n",
      "The MSE for the EVaR Regression with RLS warm start is for ε = 0.001 : 0.44569005317815713\n",
      "The MSE for the EVaR_ℓ1 Regression is for ε = 0.001 : 0.3701251291858531\n",
      "The MSE for the EVaR_ℓ1 Regression with RLS warm start is for ε = 0.001 : 0.368397352039304\n"
     ]
    }
   ],
   "source": [
    "println(\"########## The test scores are: ##########\")\n",
    "println(\"The MSE for the Regularized Least Squares is : \", \n",
    "    calculate_MSE(X_test, Y_test, w_opt_RLS))\n",
    "println(\"The MSE for the Stable Regression is : \", \n",
    "    calculate_MSE(X_test, Y_test, w_opt_SR))\n",
    "println(\"The MSE for the EVaR Regression is for ε = 0.001 : \", \n",
    "    calculate_MSE(X_test, Y_test, w_opt_EVaR))\n",
    "println(\"The MSE for the EVaR Regression with RLS warm start is for ε = 0.001 : \", \n",
    "    calculate_MSE(X_test, Y_test, w_opt_EVaR_with_warmstart))\n",
    "println(\"The MSE for the EVaR_ℓ1 Regression is for ε = 0.001 : \", \n",
    "    calculate_MSE(X_test, Y_test, w_opt_EVaR_ℓ1))\n",
    "println(\"The MSE for the EVaR_ℓ1 Regression with RLS warm start is for ε = 0.001 : \", \n",
    "    calculate_MSE(X_test, Y_test, w_opt_EVaR_ℓ1_with_warmstart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T14:25:05.431000-05:00",
     "start_time": "2019-12-03T17:59:41.050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## The training scores are: ##########\n",
      "The MAE for the Regularized Least Squares is : 0.3516200726221749\n",
      "The MAE for the Stable Regression is : 0.45405267687334855\n",
      "The MAE for the EVaR Regression is for ε = 0.001 : 0.5448673046523884\n",
      "The MAE for the EVaR Regression with RLS warm start is for ε = 0.001 : 0.5439425559456769\n",
      "The MAE for the EVaR_ℓ1 Regression is for ε = 0.001 : 0.49416648266580687\n",
      "The MAE for the EVaR_ℓ1 Regression with RLS warm start is for ε = 0.001 : 0.5045190900273672\n"
     ]
    }
   ],
   "source": [
    "println(\"########## The training scores are: ##########\")\n",
    "println(\"The MAE for the Regularized Least Squares is : \", \n",
    "    calculate_MAE(X_train_RLS, Y_train_RLS, w_opt_RLS))\n",
    "println(\"The MAE for the Stable Regression is : \", \n",
    "    calculate_MAE(X_train_SR, Y_train_SR, w_opt_SR))\n",
    "println(\"The MAE for the EVaR Regression is for ε = 0.001 : \", \n",
    "    calculate_MAE(X_train_EVaR, Y_train_EVaR, w_opt_EVaR))\n",
    "println(\"The MAE for the EVaR Regression with RLS warm start is for ε = 0.001 : \", \n",
    "    calculate_MAE(X_train_EVaR_with_warmstart, Y_train_EVaR_with_warmstart, w_opt_EVaR_with_warmstart))\n",
    "println(\"The MAE for the EVaR_ℓ1 Regression is for ε = 0.001 : \", \n",
    "    calculate_MAE(X_train_EVaR_ℓ1, Y_train_EVaR_ℓ1, w_opt_EVaR_ℓ1))\n",
    "println(\"The MAE for the EVaR_ℓ1 Regression with RLS warm start is for ε = 0.001 : \", \n",
    "    calculate_MAE(X_train_EVaR_ℓ1_with_warmstart, Y_train_EVaR_ℓ1_with_warmstart, w_opt_EVaR_ℓ1_with_warmstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T14:25:05.462000-05:00",
     "start_time": "2019-12-03T17:59:41.241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## The validation scores are: ##########\n",
      "The MAE for the Regularized Least Squares is : 0.34530884741499285\n",
      "The MAE for the Stable Regression is : 0.07218983785787313\n",
      "The MAE for the EVaR Regression is for ε = 0.001 : 0.07968070659186796\n",
      "The MAE for the EVaR Regression with RLS warm start is for ε = 0.001 : 0.08003049406523387\n",
      "The MAE for the EVaR_ℓ1 Regression is for ε = 0.001 : 0.0643100128769752\n",
      "The MAE for the EVaR_ℓ1 Regression with RLS warm start is for ε = 0.001 : 0.06154147408153959\n"
     ]
    }
   ],
   "source": [
    "println(\"########## The validation scores are: ##########\")\n",
    "println(\"The MAE for the Regularized Least Squares is : \", \n",
    "    calculate_MAE(X_val_RLS, Y_val_RLS, w_opt_RLS))\n",
    "println(\"The MAE for the Stable Regression is : \", \n",
    "    calculate_MAE(X_val_SR, Y_val_SR, w_opt_SR))\n",
    "println(\"The MAE for the EVaR Regression is for ε = 0.001 : \", \n",
    "    calculate_MAE(X_val_EVaR, Y_val_EVaR, w_opt_EVaR))\n",
    "println(\"The MAE for the EVaR Regression with RLS warm start is for ε = 0.001 : \", \n",
    "    calculate_MAE(X_val_EVaR_with_warmstart, Y_val_EVaR_with_warmstart, w_opt_EVaR_with_warmstart))\n",
    "println(\"The MAE for the EVaR_ℓ1 Regression is for ε = 0.001 : \", \n",
    "    calculate_MAE(X_val_EVaR_ℓ1, Y_val_EVaR_ℓ1, w_opt_EVaR_ℓ1))\n",
    "println(\"The MAE for the EVaR_ℓ1 Regression with RLS warm start is for ε = 0.001 : \", \n",
    "    calculate_MAE(X_val_EVaR_ℓ1_with_warmstart, Y_val_EVaR_ℓ1_with_warmstart, w_opt_EVaR_ℓ1_with_warmstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T14:25:05.475000-05:00",
     "start_time": "2019-12-03T17:59:41.406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## The test scores are (MAE): ##########\n",
      "The MAE for the Regularized Least Squares is : 0.4159548259149143\n",
      "The MAE for the Stable Regression is : 0.398252535412881\n",
      "The MAE for the EVaR Regression is for ε = 0.001 : 0.4767091032858155\n",
      "The MAE for the EVaR Regression with RLS warm start is for ε = 0.001 : 0.4757064328478016\n",
      "The MAE for the EVaR_ℓ1 Regression is for ε = 0.001 : 0.43315211313231244\n",
      "The MAE for the EVaR_ℓ1 Regression with RLS warm start is for ε = 0.001 : 0.4431392613400392\n"
     ]
    }
   ],
   "source": [
    "println(\"########## The test scores are (MAE): ##########\")\n",
    "println(\"The MAE for the Regularized Least Squares is : \", \n",
    "    calculate_MAE(X_test, Y_test, w_opt_RLS))\n",
    "println(\"The MAE for the Stable Regression is : \", \n",
    "    calculate_MAE(X_test, Y_test, w_opt_SR))\n",
    "println(\"The MAE for the EVaR Regression is for ε = 0.001 : \", \n",
    "    calculate_MAE(X_test, Y_test, w_opt_EVaR))\n",
    "println(\"The MAE for the EVaR Regression with RLS warm start is for ε = 0.001 : \", \n",
    "    calculate_MAE(X_test, Y_test, w_opt_EVaR_with_warmstart))\n",
    "println(\"The MAE for the EVaR_ℓ1 Regression is for ε = 0.001 : \", \n",
    "    calculate_MAE(X_test, Y_test, w_opt_EVaR_ℓ1))\n",
    "println(\"The MAE for the EVaR_ℓ1 Regression with RLS warm start is for ε = 0.001 : \", \n",
    "    calculate_MAE(X_test, Y_test, w_opt_EVaR_ℓ1_with_warmstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T23:40:34-05:00",
     "start_time": "2019-12-03T04:40:33.991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training scores are: \n",
      "The MSE for the Regularized Least Squares is : 0.28237743438596236\n",
      "The MSE for the Stable Regression is : 0.38160426678251924\n",
      "The MSE for the EVaR Regression is for ε = 0.1 : 0.47225361837674856\n",
      "The MSE for the EVaR Regression with RLS warm start is for ε = 0.1 : 0.46733409736144577\n"
     ]
    }
   ],
   "source": [
    "println(\"########## The training scores are: ##########\")\n",
    "println(\"The MSE for the Regularized Least Squares is : \", \n",
    "    calculate_MSE(X_train_RLS, Y_train_RLS, w_opt_RLS))\n",
    "println(\"The MSE for the Stable Regression is : \", \n",
    "    calculate_MSE(X_train_SR, Y_train_SR, w_opt_SR))\n",
    "println(\"The MSE for the EVaR Regression is for ε = 0.1 : \", \n",
    "    calculate_MSE(X_train_EVaR, Y_train_EVaR, w_opt_EVaR))\n",
    "println(\"The MSE for the EVaR Regression with RLS warm start is for ε = 0.1 : \", \n",
    "    calculate_MSE(X_train_EVaR_with_warmstart, Y_train_EVaR_with_warmstart, w_opt_EVaR_with_warmstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T23:40:43.480000-05:00",
     "start_time": "2019-12-03T04:40:43.475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation scores are:\n",
      "The MSE for the Regularized Least Squares is : 0.22807812578839193\n",
      "The MSE for the Stable Regression is : 0.0068670814996991516\n",
      "The MSE for the EVaR Regression is for ε = 0.1 : 0.009770436299351223\n",
      "The MSE for the EVaR Regression with RLS warm start is for ε = 0.1 : 0.009786778984419287\n"
     ]
    }
   ],
   "source": [
    "println(\"########## The validation scores are: ##########\")\n",
    "println(\"The MSE for the Regularized Least Squares is : \", \n",
    "    calculate_MSE(X_val_RLS, Y_val_RLS, w_opt_RLS))\n",
    "println(\"The MSE for the Stable Regression is : \", \n",
    "    calculate_MSE(X_val_SR, Y_val_SR, w_opt_SR))\n",
    "println(\"The MSE for the EVaR Regression is for ε = 0.1 : \", \n",
    "    calculate_MSE(X_val_EVaR, Y_val_EVaR, w_opt_EVaR))\n",
    "println(\"The MSE for the EVaR Regression with RLS warm start is for ε = 0.1 : \", \n",
    "    calculate_MSE(X_val_EVaR_with_warmstart, Y_val_EVaR_with_warmstart, w_opt_EVaR_with_warmstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T23:40:46.372000-05:00",
     "start_time": "2019-12-03T04:40:46.363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test scores are:\n",
      "The MSE for the Regularized Least Squares is : 0.40677205711878867\n",
      "The MSE for the Stable Regression is : 0.3769294123159734\n",
      "The MSE for the EVaR Regression is for ε = 0.1 : 0.6126187879218311\n",
      "The MSE for the EVaR Regression with RLS warm start is for ε = 0.1 : 0.6016956516704023\n"
     ]
    }
   ],
   "source": [
    "println(\"########## The test scores are: ##########\")\n",
    "println(\"The MSE for the Regularized Least Squares is : \", \n",
    "    calculate_MSE(X_test, Y_test, w_opt_RLS))\n",
    "println(\"The MSE for the Stable Regression is : \", \n",
    "    calculate_MSE(X_test, Y_test, w_opt_SR))\n",
    "println(\"The MSE for the EVaR Regression is for ε = 0.1 : \", \n",
    "    calculate_MSE(X_test, Y_test, w_opt_EVaR))\n",
    "println(\"The MSE for the EVaR Regression with RLS warm start is for ε = 0.1 : \", \n",
    "    calculate_MSE(X_test, Y_test, w_opt_EVaR_with_warmstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T18:57:51.381000-05:00",
     "start_time": "2019-12-01T23:57:45.105Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n",
      "55669.86224993145\n",
      "202954.57523898082\n",
      "465807.7944702865\n",
      "571777.629694811\n",
      "649372.3805206266\n",
      "657711.9404003171\n",
      "657724.9043249263\n",
      "654487.4375204031\n",
      "645880.5971714322\n",
      "641509.4710914962\n",
      "632510.6203716445\n",
      "628185.3419095788\n",
      "619651.4299285613\n",
      "615487.7301913105\n",
      "607460.3065848325\n",
      "603457.3143498494\n",
      "595898.6664486566\n",
      "592044.7124320026\n",
      "584915.7360894731\n",
      "581199.3953057412\n",
      "574465.8930382177\n",
      "570876.731423585\n",
      "564508.5028002661\n",
      "561036.8191874583\n",
      "555006.3864612373\n",
      "551642.9345553475\n",
      "545924.5636888716\n",
      "542660.3421086599\n",
      "537229.3672970065\n",
      "534055.4713944199\n",
      "528887.8646410621\n",
      "525795.3849264857\n",
      "520867.50880704256\n",
      "517847.46124352125\n",
      "513135.94838628784\n",
      "510179.2235601897\n",
      "505660.9344289479\n",
      "502758.2546696834\n",
      "498410.27440626704\n",
      "495552.14999618987\n",
      "491351.7942481315\n",
      "488528.4716846908\n",
      "484453.27959323645\n",
      "481654.6762317032\n",
      "477682.37545838073\n",
      "474897.99561683345\n",
      "471006.4290981776\n",
      "468225.25672799477\n",
      "464392.2636420062\n",
      "461602.62584298797\n",
      "457805.87003345083\n",
      "454995.2638672927\n",
      "451212.0016775705\n",
      "448366.8736439792\n",
      "444573.64959741343\n",
      "441679.11231989885\n",
      "437851.36489263456\n",
      "434890.8282084129\n",
      "431002.3781149583\n",
      "427957.0604732445\n",
      "423979.4386147955\n",
      "420827.70701784024\n",
      "416729.25523878436\n",
      "413445.7135782843\n",
      "409190.3526595519\n",
      "405744.5513207055\n",
      "401290.04614217085\n",
      "397644.6053219742\n",
      "392940.04569770454\n",
      "389047.8419534463\n",
      "384029.8572257155\n",
      "379829.6578443341\n",
      "374416.5062948991\n",
      "369825.92098237993\n",
      "363907.8488797938\n",
      "358811.4102585552\n",
      "352234.10965368536\n",
      "346461.97810576274\n",
      "338996.4575884047\n",
      "332283.78581764246\n",
      "323567.4301750639\n",
      "315470.3844131784\n",
      "304881.2516317941\n",
      "294585.82437305554\n",
      "280945.2723102526\n",
      "266779.55659550213\n",
      "247563.1165213309\n",
      "225611.74835526472\n",
      "194736.34345111734\n",
      "155396.2399951583\n",
      "101620.53811130066\n",
      "44758.7719519243\n",
      "9734.0986414345\n",
      "819.0772643790438\n",
      "48.7023713326992\n",
      "5.383394311240253\n",
      "3.1965809711209277\n",
      "3.070219918187252\n",
      "3.046054952836473\n",
      "3.0274821125053344\n",
      "3.0092462987255786\n",
      "2.991178823815771\n",
      "2.9732490011263506\n",
      "2.9554586375014633\n",
      "2.9378054991375477\n",
      "2.920288420461986\n",
      "2.9029060283185966\n",
      "2.8856570157854065\n",
      "2.86854008121311\n",
      "2.851553941313548\n",
      "2.834697327991549\n",
      "2.8179689887511103\n",
      "2.8013676863234944\n",
      "2.784892198470472\n",
      "2.7685413177542966\n",
      "2.7523138513198013\n",
      "2.736208620678501\n",
      "2.7202244614968802\n",
      "2.7043602233883393\n",
      "2.688614769708848\n",
      "2.672986977355788\n",
      "2.657475736570965\n",
      "2.6420799507463038\n",
      "2.626798536233345\n",
      "2.611630422155936\n",
      "2.596574550225985\n",
      "2.581629874562566\n",
      "2.5667953615140084\n",
      "2.552069989482917\n",
      "2.537452748754458\n",
      "2.522942641327182\n",
      "2.508538680746999\n",
      "2.494239891943731\n",
      "2.4800453110705853\n",
      "2.465953985346246\n",
      "2.4519649728994777\n",
      "2.4380773426165447\n",
      "2.424290173991004\n",
      "2.410602556976054\n",
      "2.3970135918392197\n",
      "2.3835223890196353\n",
      "2.3701280689874147\n",
      "2.3568297621055483\n",
      "2.343626608493968\n",
      "2.33051775789574\n",
      "2.317502369545602\n",
      "2.3045796120405306\n",
      "2.2917486632123936\n",
      "2.2790087100026746\n",
      "2.266358948339314\n",
      "2.253798583015295\n",
      "2.2413268275694405\n",
      "2.2289429041688766\n",
      "2.2166460434935518\n",
      "2.2044354846224845\n",
      "2.1923104749218663\n",
      "2.180270269934826\n",
      "2.168314133273138\n",
      "2.1564413365104507\n",
      "2.1446511590772124\n",
      "2.132942888157317\n",
      "2.12131581858636\n",
      "2.109769252751354\n",
      "2.098302500492192\n",
      "2.086914879004418\n",
      "2.0756057127437186\n",
      "2.064374333331745\n",
      "2.0532200794634132\n",
      "2.0421422968156087\n",
      "2.0311403379573933\n",
      "2.0202135622614446\n",
      "2.0093613358169047\n",
      "1.9985830313435695\n",
      "1.9878780281073407\n",
      "1.977245711836974\n",
      "1.9666854746421158\n",
      "1.9561967149324884\n",
      "1.9457788373384022\n",
      "1.9354312526323\n",
      "1.9251533776516603\n",
      "1.914944635222916\n",
      "1.9048044540865594\n",
      "1.8947322688232986\n",
      "1.88472751978139\n",
      "1.8747896530050192\n",
      "1.864918120163674\n",
      "1.855112378482639\n",
      "1.8453718906744445\n",
      "1.8356961248713515\n",
      "1.8260845545588114\n",
      "1.816536658509961\n",
      "1.8070519207208335\n",
      "1.7976298303469107\n",
      "1.7882698816401672\n",
      "1.7789715738873089\n",
      "1.7697344113487787\n",
      "1.760557903198682\n",
      "1.751441563465528\n",
      "1.7423849109739118\n",
      "1.7333874692868432\n",
      "1.7244487666491102\n",
      "1.7155683359313185\n",
      "1.7067457145747709\n",
      "1.6979804445370783\n",
      "1.6892720722385908\n",
      "1.680620148509538\n",
      "1.6720242285379616\n",
      "1.6634838718183258\n",
      "1.6549986421008709\n",
      "1.6465681073416434\n",
      "1.6381918396533328\n",
      "1.629869415256574\n",
      "1.6216004144321632\n",
      "1.6133844214737976\n",
      "1.6052210246414484\n",
      "1.597109816115449\n",
      "1.589050391951224\n",
      "1.5810423520345416\n",
      "1.573085300037438\n",
      "1.5651788433748082\n",
      "1.5573225931614203\n",
      "1.54951616416971\n",
      "1.5417591747879\n",
      "1.5340512469790661\n",
      "1.5263920062402985\n",
      "1.5187810815627323\n",
      "1.5112181053920655\n",
      "1.503702713589462\n",
      "1.4962345453931545\n",
      "1.48881324338045\n",
      "1.4814384534302543\n",
      "1.4741098246861533\n",
      "1.4668270095199203\n",
      "1.4595896634955239\n",
      "1.452397445333676\n",
      "1.445250016876652\n",
      "1.438147043053856\n",
      "1.4310881918476286\n",
      "1.4240731342595172\n",
      "1.4171015442771593\n",
      "1.4101730988413577\n",
      "1.403287477813716\n",
      "1.3964443639447415\n",
      "1.389643442842232\n",
      "1.3828844029402052\n",
      "1.3761669354680826\n",
      "1.3694907344203744\n",
      "1.362855496526792\n",
      "1.3562609212225887\n",
      "1.349706710619425\n",
      "1.3431925694765476\n",
      "1.3367182051723456\n",
      "1.3302833276762067\n",
      "1.3238876495208929\n",
      "1.3175308857750694\n",
      "1.311212754016348\n",
      "1.3049329743044886\n",
      "1.2986912691552028\n",
      "1.2924873635139609\n",
      "1.2863209847304202\n",
      "1.2801918625330067\n",
      "1.2740997290038507\n",
      "1.268044318554038\n",
      "1.262025367899211\n",
      "1.2560426160353682\n",
      "1.2500958042151147\n",
      "1.2441846759240371\n",
      "1.2383089768575424\n",
      "1.2324684548978015\n",
      "1.226662860091141\n",
      "1.2208919446255986\n",
      "1.2151554628088606\n",
      "1.2094531710463088\n",
      "1.2037848278195236\n",
      "1.1981501936648713\n",
      "1.1925490311525502\n",
      "1.1869811048656331\n",
      "1.1814461813796724\n",
      "1.1759440292422163\n",
      "1.1704744189528977\n",
      "1.1650371229435115\n",
      "1.1596319155584647\n",
      "1.1542585730354182\n",
      "1.1489168734861706\n",
      "1.1436065968777729\n",
      "1.1383275250138682\n",
      "1.133079441516199\n",
      "1.1278621318064592\n",
      "1.1226753830882346\n",
      "1.1175189843292146\n",
      "1.1123927262436297\n",
      "1.1072964012748368\n",
      "1.1022298035782032\n",
      "1.0971927290040653\n",
      "1.0921849750810313\n",
      "1.0872063409993356\n",
      "1.0822566275945047\n",
      "1.0773356373311525\n",
      "1.0724431742869767\n",
      "1.0675790441369186\n",
      "1.0627430541376082\n",
      "1.0579350131118268\n",
      "1.053154731433231\n",
      "1.048402021011361\n",
      "1.0436766952765788\n",
      "1.0389785691654518\n",
      "1.0343074591060246\n",
      "1.0296631830035554\n",
      "1.0250455602261475\n",
      "1.0204544115907057\n",
      "1.0158895593490094\n",
      "1.0113508271739835\n",
      "1.0068380401459662\n",
      "1.0023510247393816\n",
      "0.997889608809357\n",
      "0.9934536215785904\n",
      "0.9890428936243342\n",
      "0.9846572568655513\n",
      "0.9802965445501484\n",
      "0.9759605912424589\n",
      "0.971649232810806\n",
      "0.9673623064151321\n",
      "0.9630996504949438\n",
      "0.9588611047571786\n",
      "0.9546465101644251\n",
      "0.95045570892312\n",
      "0.9462885444718484\n",
      "0.9421448614699673\n",
      "0.9380245057861483\n",
      "0.9339273244871718\n",
      "0.9298531658267634\n",
      "0.9258018792346294\n",
      "0.9217733153055859\n",
      "0.9177673257887164\n",
      "0.91378376357684\n",
      "0.9098224826958731\n",
      "0.9058833382945152\n",
      "0.9019661866338574\n",
      "0.898070885077246\n",
      "0.8941972920801982\n",
      "0.8903452671804177\n",
      "0.8865146709879484\n",
      "0.8827053651753776\n",
      "0.8789172124682538\n",
      "0.8751500766354441\n",
      "0.8714038224797803\n",
      "0.8676783158286604\n",
      "0.8639734235248206\n",
      "0.860289013417166\n",
      "0.8566249543517575\n",
      "0.8529811161628249\n",
      "0.8493573696639163\n",
      "0.8457535866391631\n",
      "0.8421696398345427\n",
      "0.8386054029493741\n",
      "0.8350607506277598\n",
      "0.8315355584502336\n",
      "0.8280297029254254\n",
      "0.8245430614818077\n",
      "0.8210755124596246\n",
      "0.8176269351027808\n",
      "0.81419720955088\n",
      "0.8107862168313176\n",
      "0.807393838851565\n",
      "0.8040199583913167\n",
      "0.8006644590949221\n",
      "0.7973272254638312\n",
      "0.7940081428490237\n",
      "0.7907070974437045\n",
      "0.7874239762758848\n",
      "0.7841586672011538\n",
      "0.7809110588955249\n",
      "0.7776810408482544\n",
      "0.7744685033548566\n",
      "0.7712733375101273\n",
      "0.7680954352012161\n",
      "0.7649346891008646\n",
      "0.7617909926605763\n",
      "0.7586642401039738\n",
      "0.7555543264201803\n",
      "0.7524611473572229\n",
      "0.7493845994156013\n",
      "0.7463245798418202\n",
      "0.7432809866220564\n",
      "0.7402537184758815\n",
      "0.7372426748499603\n",
      "0.7342477559119759\n",
      "0.7312688625444453\n",
      "0.7283058963387281\n",
      "0.7253587595890151\n",
      "0.7224273552863899\n",
      "0.7195115871129936\n",
      "0.7166113594361934\n",
      "0.7137265773028298\n",
      "0.7108571464335472\n",
      "0.708002973217123\n",
      "0.705163964704901\n",
      "0.7023400286052571\n",
      "0.6995310732781447\n",
      "0.6967370077296446\n",
      "0.6939577416066025\n",
      "0.6911931851913512\n",
      "0.6884432493964038\n",
      "0.6857078457592641\n",
      "0.6829868864372435\n",
      "0.6802802842023935\n",
      "0.6775879524363999\n",
      "0.6749098051255942\n",
      "0.6722457568559839\n",
      "0.6695957228083458\n",
      "0.6669596187533309\n",
      "0.6643373610466677\n",
      "0.661728866624401\n",
      "0.6591340529980908\n",
      "0.6565528382502418\n",
      "0.6539851410295523\n",
      "0.6514308805463916\n",
      "0.6488899765682138\n",
      "0.646362349415067\n",
      "0.6438479199551179\n",
      "0.6413466096002425\n",
      "0.6388583403016125\n",
      "0.6363830345454214\n",
      "0.6339206153484993\n",
      "0.6314710062541198\n",
      "0.6290341313277695\n",
      "0.6266099151529552\n",
      "0.6241982828270656\n",
      "0.6217991599572964\n",
      "0.6194124726565545\n",
      "0.617038147539447\n",
      "0.6146761117183279\n",
      "0.6123262927992896\n",
      "0.6099886188782926\n",
      "0.6076630185372861\n",
      "0.6053494208403443\n",
      "0.6030477553298993\n",
      "0.600757952022928\n",
      "0.5984799414072597\n",
      "0.5962136544378476\n",
      "0.5939590225331113\n",
      "0.5917159775713245\n",
      "0.5894844518869697\n",
      "0.5872643782672299\n",
      "0.5850556899484219\n",
      "0.582858320612472\n",
      "0.5806722043835156\n",
      "0.5784972758244079\n",
      "0.5763334699333171\n",
      "0.5741807221403773\n",
      "0.5720389683043241\n",
      "0.569908144709202\n",
      "0.5677881880610471\n",
      "0.5656790354846668\n",
      "0.5635806245203854\n",
      "0.5614928931208754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5594157796479656\n",
      "0.5573492228695406\n",
      "0.5552931619563722\n",
      "0.5532475364790868\n",
      "0.5512122864050993\n",
      "0.5491873520955671\n",
      "0.547172674302416\n",
      "0.5451681941653258\n",
      "0.5431738532088413\n",
      "0.5411895933394076\n",
      "0.5392153568424732\n",
      "0.5372510863796582\n",
      "0.5352967249858696\n",
      "0.5333522160664944\n",
      "0.53141750339462\n",
      "0.5294925311082607\n",
      "0.5275772437075883\n",
      "0.5256715860522359\n",
      "0.5237755033585919\n",
      "0.5218889411971385\n",
      "0.5200118454897723\n",
      "0.5181441625071955\n",
      "0.516285838866337\n",
      "0.5144368215277241\n",
      "0.5125970577929518\n",
      "0.5107664953021344\n",
      "0.5089450820314052\n",
      "0.5071327662904103\n",
      "0.5053294967198249\n",
      "0.5035352222889444\n",
      "0.501749892293223\n",
      "0.49997345635186524\n",
      "0.4982058644054444\n",
      "0.4964470667135589\n",
      "0.4946970138524425\n",
      "0.4929556567126775\n",
      "0.49122294649685433\n",
      "0.48949883471730654\n",
      "0.48778327319386194\n",
      "0.48607621405153684\n",
      "0.4843776097183594\n",
      "0.4826874129231576\n",
      "0.4810055766933252\n",
      "0.4793320543526885\n",
      "0.4776667995193484\n",
      "0.4760097661035332\n",
      "0.47436090830548083\n",
      "0.4727201806133559\n",
      "0.4710875378011276\n",
      "0.46946293492657115\n",
      "0.46784632732914344\n",
      "0.466237670628016\n",
      "0.4646369207200295\n",
      "0.46304403377770137\n",
      "0.46145896624725363\n",
      "0.45988167484663633\n",
      "0.4583121165635973\n",
      "0.4567502486537441\n",
      "0.4551960286386336\n",
      "0.4536494143038545\n",
      "0.45211036369717766\n",
      "0.4505788351266485\n",
      "0.4490547871587733\n",
      "0.4475381786166703\n",
      "0.4460289685782155\n",
      "0.44452711637429143\n",
      "0.4430325815869589\n",
      "0.4415453240476885\n",
      "0.44006530383561143\n",
      "0.43859248127574085\n",
      "0.43712681693726496\n",
      "0.4356682716318251\n",
      "0.4342168064117935\n",
      "0.43277238256860734\n",
      "0.4313349616310685\n",
      "0.42990450536368985\n",
      "0.4284809757650325\n",
      "0.42706433506609953\n",
      "0.425654545728681\n",
      "0.4242515704437428\n",
      "0.4228553721298559\n",
      "0.4214659139315876\n",
      "0.4200831592179265\n",
      "0.4187070715807664\n",
      "0.4173376148332887\n",
      "0.41597475300848924\n",
      "0.41461845035761963\n",
      "0.4132686713487007\n",
      "0.41192538066500234\n",
      "0.4105885432035854\n",
      "0.40925812407378503\n",
      "0.4079340885958066\n",
      "0.40661640229922036\n",
      "0.40530503092154585\n",
      "0.40399994040683884\n",
      "0.40270109690424627\n",
      "0.4014084667666061\n",
      "0.40012201654908053\n",
      "0.3988417130077421\n",
      "0.3975675230982115\n",
      "0.396299413974298\n",
      "0.3950373529866509\n",
      "0.393781307681408\n",
      "0.3925312457988972\n",
      "0.3912871352722631\n",
      "0.39004894422621267\n",
      "0.3888166409756834\n",
      "0.3875901940245681\n",
      "0.38636957206443706\n",
      "0.3851547439732615\n",
      "0.3839456788141578\n",
      "0.38274234583415073\n",
      "0.3815447144629097\n",
      "0.38035275431154864\n",
      "0.379166435171385\n",
      "0.377985727012735\n",
      "0.3768105999837096\n",
      "0.37564102440903585\n",
      "0.3744769707888596\n",
      "0.3733184097975757\n",
      "0.3721653122826662\n",
      "0.3710176492635453\n",
      "0.3698753919304128\n",
      "0.3687385116430993\n",
      "0.3676069799299737\n",
      "0.3664807684867837\n",
      "0.3653598491755677\n",
      "0.364244194023547\n",
      "0.36313377522202184\n",
      "0.3620285651252977\n",
      "0.3609285362495895\n",
      "0.3598336612719784\n",
      "0.3587439130293098\n",
      "0.35765926451718394\n",
      "0.3565796888888808\n",
      "0.3555051594543153\n",
      "0.3544356496790416\n",
      "0.35337113318320873\n",
      "0.352311583740518\n",
      "0.35125697527727245\n",
      "0.35020728187135136\n",
      "0.34916247775118253\n",
      "0.3481225372948211\n",
      "0.3470874350289374\n",
      "0.3460571456278356\n",
      "0.34503164391251057\n",
      "0.3440109048496971\n",
      "0.3429949035509032\n",
      "0.3419836152714792\n",
      "0.3409770154096809\n",
      "0.3399750795057394\n",
      "0.33897778324094413\n",
      "0.33798510243672886\n",
      "0.336997013053766\n",
      "0.3360134911910608\n",
      "0.3350345130850564\n",
      "0.3340600551087629\n",
      "0.333090093770844\n",
      "0.3321246057147891\n",
      "0.3311635677180099\n",
      "0.33020695669097855\n",
      "0.32925474967640095\n",
      "0.3283069238483296\n",
      "0.32736345651136817\n",
      "0.32642432509978386\n",
      "0.3254895071767271\n",
      "0.32455898043335113\n",
      "0.32363272268805676\n",
      "0.32271071188563316\n",
      "0.32179292609646143\n",
      "0.3208793435157455\n",
      "0.3199699424626566\n",
      "0.31906470137960624\n",
      "0.3181635988314259\n",
      "0.31726661350459684\n",
      "0.31637372420649873\n",
      "0.3154849098646019\n",
      "0.31460014952574955\n",
      "0.31371942235537437\n",
      "0.3128427076367664\n",
      "0.3119699847703091\n",
      "0.31110123327276223\n",
      "0.31023643277650803\n",
      "0.3093755630288416\n",
      "0.30851860389122987\n",
      "0.3076655353386031\n",
      "0.30681633745864223\n",
      "0.3059709904510731\n",
      "0.3051294746269525\n",
      "0.30429177040798094\n",
      "0.3034578583257994\n",
      "0.3026277190213173\n",
      "0.3018013332440189\n",
      "0.3009786818512825\n",
      "0.30015974580770655\n",
      "0.2993445061844562\n",
      "0.2985329441585756\n",
      "0.2977250410123574\n",
      "0.2969207781326619\n",
      "0.2961201370102732\n",
      "0.29532309923926686\n",
      "0.2945296465163544\n",
      "0.29373976064025387\n",
      "0.2929534235110577\n",
      "0.2921706171296029\n",
      "0.2913913235968521\n",
      "0.2906155251132655\n",
      "0.289843203978197\n",
      "0.28907434258928094\n",
      "0.2883089234418237\n",
      "0.2875469291282019\n",
      "0.2867883423372712\n",
      "0.2860331458537683\n",
      "0.2852813225577097\n",
      "0.28453285542383644\n",
      "0.28378772752100917\n",
      "0.2830459220116329\n",
      "0.2823074221510882\n",
      "0.281572211287182\n",
      "0.2808402728595246\n",
      "0.28011159039904715\n",
      "0.2793861475273802\n",
      "0.278663927956336\n",
      "0.2779449154873351\n",
      "0.2772290940108818\n",
      "0.2765164475060124\n",
      "0.2758069600397553\n",
      "0.2751006157665875\n",
      "0.27439739892793535\n",
      "0.27369729385161184\n",
      "0.2730002849513003\n",
      "0.27230635672605796\n",
      "0.2716154937597674\n",
      "0.2709276807206417\n",
      "0.27024290236071447\n",
      "0.2695611435153267\n",
      "0.2688823891026261\n",
      "0.2682066241230684\n",
      "0.26753383365892525\n",
      "0.26686400287378237\n",
      "0.26619711701206517\n",
      "0.2655331613985326\n",
      "0.2648721214378124\n",
      "0.26421398261391077\n",
      "0.2635587304897433\n",
      "0.26290635070665724\n",
      "0.2622568289839613\n",
      "0.26161015111845887\n",
      "0.2609663029839986\n",
      "0.2603252705309841\n",
      "0.2596870397859463\n",
      "0.25905159685107154\n",
      "0.25841892790376486\n",
      "0.2577890191961776\n",
      "0.25716185705478734\n",
      "0.25653742787994993\n",
      "0.2559157181454451\n",
      "0.2552967143980578\n",
      "0.2546804032571404\n",
      "0.2540667714141718\n",
      "0.25345580563234266\n",
      "0.2528474927461264\n",
      "0.25224181966085174\n",
      "0.2516387733522943\n",
      "0.2510383408662484\n",
      "0.25044050931812\n",
      "0.24984526589251418\n",
      "0.2492525978428305\n",
      "0.24866249249085193\n",
      "0.24807493722634363\n",
      "0.24748991950664614\n",
      "0.24690742685629988\n",
      "0.2463274468666246\n",
      "0.24574996719533757\n",
      "0.24517497556616907\n",
      "0.2446024597684596\n",
      "0.24403240765679618\n",
      "0.2434648071506139\n",
      "0.24289964623381782\n",
      "0.2423369129544182\n",
      "0.24177659542413893\n",
      "0.24121868181805278\n",
      "0.24066316037421723\n",
      "0.24011001939330276\n",
      "0.23955924723821462\n",
      "0.23901083233375398\n",
      "0.2384647631662388\n",
      "0.23792102828315803\n",
      "0.23737961629280113\n",
      "0.23684051586392382\n",
      "0.23630371572538258\n",
      "0.23576920466578996\n",
      "0.2352369715331655\n",
      "0.23470700523460067\n",
      "0.23417929473590224\n",
      "0.23365382906126683\n",
      "0.23313059729293617\n",
      "0.23260958857085143\n",
      "0.23209079209234515\n",
      "0.2315741971117861\n",
      "0.23105979294025797\n",
      "0.2305475689452378\n",
      "0.23003751455027138\n",
      "0.22952961923462517\n",
      "0.2290238725330121\n",
      "0.22852026403523082\n",
      "0.2280187833858648\n",
      "0.22751942028397693\n",
      "0.22702216448277407\n",
      "0.22652700578932325\n",
      "0.2260339340642238\n",
      "0.22554293922130494\n",
      "0.22505401122732296\n",
      "0.22456714010165366\n",
      "0.22408231591600847\n",
      "0.2235995287941067\n",
      "0.22311876891140373\n",
      "0.22264002649478482\n",
      "0.22216329182226807\n",
      "0.2216885552227242\n",
      "0.2212158070755734\n",
      "0.22074503781051233\n",
      "0.22027623790721093\n",
      "0.21980939789505102\n",
      "0.21934450835281197\n",
      "0.21888155990842403\n",
      "0.21842054323866378\n",
      "0.217961449068896\n",
      "0.21750426817277468\n",
      "0.21704899137199687\n",
      "0.2165956095360132\n",
      "0.21614411358175986\n",
      "0.21569449447339217\n",
      "0.21524674322202295\n",
      "0.21480085088544035\n",
      "0.21435680856786504\n",
      "0.21391460741967835\n",
      "0.21347423863715845\n",
      "0.21303569346222678\n",
      "0.21259896318218793\n",
      "0.21216403912947956\n",
      "0.21173091268141686\n",
      "0.21129957525993023\n",
      "0.21087001833132588\n",
      "0.210442233406037\n",
      "0.210016212038366\n",
      "0.2095919458262532\n",
      "0.20916942641101363\n",
      "0.2087486454771069\n",
      "0.20832959475190305\n",
      "0.20791226600541285\n",
      "0.2074966510500834\n",
      "0.20708274174053906\n",
      "0.20667052997335975\n",
      "0.20626000768682948\n",
      "0.20585116686071678\n",
      "0.20544399951604558\n",
      "0.2050384977148529\n",
      "0.20463465355996713\n",
      "0.20423245919478863\n",
      "0.2038319068030498\n",
      "0.20343298860859538\n",
      "0.20303569687516573\n",
      "0.20264002390616906\n",
      "0.20224596204445855\n",
      "0.20185350367212687\n",
      "0.20146264121026683\n",
      "0.20107336711877855\n",
      "0.20068567389613387\n",
      "0.2002995540791824\n",
      "0.19991500024292047\n",
      "0.19953200500029056\n",
      "0.19915056100197018\n",
      "0.1987706609361628\n",
      "0.1983922975283933\n",
      "0.1980154635412879\n",
      "0.19764015177439453\n",
      "0.19726635506396023\n",
      "0.1968940662827281\n",
      "0.19652327833975114\n",
      "0.19615398418017319\n",
      "0.1957861767850516\n",
      "0.1954198491711396\n",
      "0.1950549943907052\n",
      "0.19469160553132514\n",
      "0.19432967571569792\n",
      "0.19396919810145155\n",
      "0.19361016588094385\n",
      "0.19325257228108006\n",
      "0.19289641056312398\n",
      "0.19254167402250022\n",
      "0.19218835598861905\n",
      "0.19183644982468487\n",
      "0.19148594892750956\n",
      "0.19113684672733477\n",
      "0.19078913668763864\n",
      "0.19044281230497043\n",
      "0.1900978671087517\n",
      "0.1897542946611102\n",
      "0.18941208855670003\n",
      "0.18907124242251877\n",
      "0.18873174991773373\n",
      "0.18839360473351313\n",
      "0.18805680059284036\n",
      "0.18772133125034876\n",
      "0.18738719049214858\n",
      "0.1870543721356561\n",
      "0.18672287002941934\n",
      "0.18639267805296048\n",
      "0.18606379011659288\n",
      "0.18573620016126013\n",
      "0.18540990215837783\n",
      "0.18508489010966017\n",
      "0.1847611580469523\n",
      "0.1844387000320791\n",
      "0.1841175101566724\n",
      "0.1837975825420212\n",
      "0.1834789113388898\n",
      "0.18316149072738916\n",
      "0.18284531491679407\n",
      "0.1825303781453984\n",
      "0.1822166746803489\n",
      "0.18190419881749645\n",
      "0.1815929448812499\n",
      "0.18128290722439666\n",
      "0.18097408022797543\n",
      "0.1806664583011195\n",
      "0.18036003588088848\n",
      "0.1800548074321389\n",
      "0.17975076744736437\n",
      "0.179447910446551\n",
      "0.17914623097702714\n",
      "0.17884572361331558\n",
      "0.17854638295699335\n",
      "0.17824820363654242\n",
      "0.17795118030720372\n",
      "0.17765530765084445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17736058037579702\n",
      "0.17706699321673847\n",
      "0.1767745409345319\n",
      "0.17648321831609992\n",
      "0.17619302017427238\n",
      "0.17590394134766102\n",
      "0.17561597670051882\n",
      "0.17532912112258886\n",
      "0.17504336952899135\n",
      "0.17475871686007316\n",
      "0.17447515808127778\n",
      "0.1741926881830091\n",
      "0.17391130218050022\n",
      "0.17363099511368701\n",
      "0.17335176204706867\n",
      "0.17307359806957545\n",
      "0.1727964982944535\n",
      "0.1725204578591145\n",
      "0.1722454719250266\n",
      "0.17197153567757667\n",
      "0.17169864432593887\n",
      "0.17142679310297046\n",
      "0.17115597726505427\n",
      "0.17088619209200395\n",
      "0.1706174328869182\n",
      "0.1703496949760706\n",
      "0.17008297370877992\n",
      "0.16981726445729434\n",
      "0.16955256261666185\n",
      "0.169288863604623\n",
      "0.16902616286147681\n",
      "0.16876445584996255\n",
      "0.16850373805516317\n",
      "0.16824400498435263\n",
      "0.16798525216691326\n",
      "0.16772747515419126\n",
      "0.16747066951939693\n",
      "0.16721483085748873\n",
      "0.166959954785051\n",
      "0.16670603694019134\n",
      "0.16645307298241124\n",
      "0.16620105859251283\n",
      "0.16594998947247586\n",
      "0.16569986134534512\n",
      "0.16545066995512256\n",
      "0.16520241106666367\n",
      "0.1649550804655558\n",
      "0.1647086739580211\n",
      "0.16446318737079724\n",
      "0.164218616551045\n",
      "0.16397495736622358\n",
      "0.1637322057039961\n",
      "0.1634903574721234\n",
      "0.1632494085983547\n",
      "0.16300935503032102\n",
      "0.1627701927354422\n",
      "0.1625319177008137\n",
      "0.1622945259331059\n",
      "0.1620580134584588\n",
      "0.1618223763223957\n",
      "0.16158761058969515\n",
      "0.16135371234432389\n",
      "0.16112067768930488\n",
      "0.16088850274663896\n",
      "0.16065718365720053\n",
      "0.16042671658063504\n",
      "0.16019709769526536\n",
      "0.15996832319799476\n",
      "0.15974038930420958\n",
      "0.15951329224768598\n",
      "0.15928702828048458\n",
      "0.1590615936728701\n",
      "0.15883698471320423\n",
      "0.1586131977078588\n",
      "0.15839022898112304\n",
      "0.15816807487510287\n",
      "0.15794673174963933\n",
      "0.15772619598220763\n",
      "0.15750646396783277\n",
      "0.15728753211899035\n",
      "0.157069396865527\n",
      "0.1568520546545642\n",
      "0.1566355019504055\n",
      "0.15641973523445546\n",
      "0.15620475100513087\n",
      "0.15599054577776253\n",
      "0.1557771160845232\n",
      "0.15556445847432576\n",
      "0.15535256951274973\n",
      "0.15514144578194852\n",
      "0.15493108388056417\n",
      "0.1547214804236408\n",
      "0.15451263204254836\n",
      "0.15430453538488942\n",
      "0.15409718711442077\n",
      "0.15389058391096488\n",
      "0.15368472247033851\n",
      "0.15347959950426063\n",
      "0.15327521174026887\n",
      "0.15307155592164645\n",
      "0.1528686288073378\n",
      "0.15266642717186796\n",
      "0.1524649478052616\n",
      "0.15226418751296686\n",
      "0.152064143115773\n",
      "0.15186481144972955\n",
      "0.15166618936607837\n",
      "0.1514682737311642\n",
      "0.15127106142636357\n",
      "0.15107454934800607\n",
      "0.1508787344072984\n",
      "0.15068361353024998\n",
      "0.1504891836575941\n",
      "0.15029544174471177\n",
      "0.1501023847615638\n",
      "0.14991000969260915\n",
      "0.1497183135367348\n",
      "0.14952729330717918\n",
      "0.14933694603146386\n",
      "0.14914726875131604\n",
      "0.148958258522596\n",
      "0.14876991241523072\n",
      "0.1485822275131345\n",
      "0.14839520091414507\n",
      "0.14820882972994634\n",
      "0.14802311108600566\n",
      "0.14783804212149143\n",
      "0.14765361998922003\n",
      "0.1474698418555705\n",
      "0.14728670490042683\n",
      "0.14710420631710405\n",
      "0.14692234331228077\n",
      "0.14674111310593121\n",
      "0.14656051293125857\n",
      "0.14638054003463186\n",
      "0.14620119167550955\n",
      "0.14602246512638015\n",
      "0.1458443576726961\n",
      "0.14566686661281064\n",
      "0.1454899892578976\n",
      "0.14531372293191058\n",
      "0.14513806497149595\n",
      "0.14496301272594334\n",
      "0.14478856355711506\n",
      "0.14461471483938276\n",
      "0.1444414639595674\n",
      "0.14426880831687267\n",
      "0.14409674532282524\n",
      "0.1439252724012133\n",
      "0.1437543869880219\n",
      "0.14358408653136936\n",
      "0.14341436849145325\n",
      "0.14324523034048378\n",
      "0.14307666956262832\n",
      "0.14290868365394369\n",
      "0.14274127012232163\n",
      "0.14257442648743182\n",
      "0.14240815028065432\n",
      "0.14224243904502698\n",
      "0.1420772903351842\n",
      "0.14191270171730588\n",
      "0.1417486707690449\n",
      "0.14158519507948045\n",
      "0.14142227224906287\n",
      "0.141259899889543\n",
      "0.14109807562393265\n",
      "0.1409367970864328\n",
      "0.14077606192239192\n",
      "0.14061586778823582\n",
      "0.14045621235142097\n",
      "0.1402970932903789\n",
      "0.1401385082944575\n",
      "0.1399804550638705\n",
      "0.13982293130963697\n",
      "0.13966593475353706\n",
      "0.13950946312804663\n",
      "0.13935351417629532\n",
      "0.13919808565200242\n",
      "0.13904317531943086\n",
      "0.1388887809533342\n",
      "0.1387349003389014\n",
      "0.13858153127170647\n",
      "0.13842867155765845\n",
      "0.13827631901294352\n",
      "0.13812447146398021\n",
      "0.13797312674736814\n",
      "0.13782228270983254\n",
      "0.13767193720817733\n",
      "0.13752208810923564\n",
      "0.13737273328981642\n",
      "0.1372238706366582\n",
      "0.13707549804637834\n",
      "0.136927613425422\n",
      "0.1367802146900163\n",
      "0.1366332997661252\n",
      "0.13648686658938664\n",
      "0.13634091310508314\n",
      "0.13619543726808148\n",
      "0.13605043704278832\n",
      "0.13590591040310404\n",
      "0.13576185533237467\n",
      "0.1356182698233478\n",
      "0.13547515187811807\n",
      "0.13533249950809256\n",
      "0.13519031073393137\n",
      "0.13504858358551428\n",
      "0.1349073161018883\n",
      "0.13476650633121953\n",
      "0.1346261523307597\n",
      "0.13448625216678653\n",
      "0.13434680391456857\n",
      "0.13420780565831936\n",
      "0.1340692554911511\n",
      "0.13393115151503132\n",
      "0.13379349184074008\n",
      "0.13365627458782683\n",
      "0.13351949788456335\n",
      "0.1333831598679075\n",
      "0.13324725868345408\n",
      "0.13311179248539337\n",
      "0.13297675943647264\n",
      "0.13284215770795013\n",
      "0.13270798547955423\n",
      "0.1325742409394423\n",
      "0.13244092228415674\n",
      "0.13230802771858918\n",
      "0.13217555545593213\n",
      "0.13204350371764584\n",
      "0.13191187073340901\n",
      "0.13178065474108636\n",
      "0.13164985398668383\n",
      "0.13151946672431022\n",
      "0.13138949121613627\n",
      "0.13125992573235928\n",
      "0.13113076855115308\n",
      "0.1310020179586413\n",
      "0.1308736722488524\n",
      "0.13074572972368265\n",
      "0.13061818869285122\n",
      "0.13049104747387374\n",
      "0.13036430439201158\n",
      "0.1302379577802444\n",
      "0.13011200597922476\n",
      "0.12998644733724393\n",
      "0.12986128021019536\n",
      "0.12973650296153483\n",
      "0.12961211396224467\n",
      "0.12948811159079812\n",
      "0.129364494233121\n",
      "0.12924126028255414\n",
      "0.12911840813982278\n",
      "0.128995936212993\n",
      "0.12887384291744294\n",
      "0.12875212667581865\n",
      "0.12863078591800803\n",
      "0.12850981908110073\n",
      "0.12838922460935032\n",
      "0.12826900095414606\n",
      "0.12814914657397214\n",
      "0.12802965993437473\n",
      "0.12791053950793319\n",
      "0.12779178377421382\n",
      "0.1276733912197458\n",
      "0.12755536033798806\n",
      "0.1274376896292867\n",
      "0.1273203776008488\n",
      "0.12720342276670793\n",
      "0.12708682364768695\n",
      "0.12697057877137033\n",
      "0.1268546866720701\n",
      "0.12673914589078772\n",
      "0.12662395497519133\n",
      "0.1265091124795732\n",
      "0.1263946169648248\n",
      "0.12628046699840043\n",
      "0.12616666115428984\n",
      "0.12605319801298207\n",
      "0.12594007616143674\n",
      "0.12582729419305075\n",
      "0.1257148507076287\n",
      "0.1256027443113512\n",
      "0.12549097361674208\n",
      "0.12537953724264453\n",
      "0.12526843381417901\n",
      "0.12515766196272501\n",
      "0.1250472203258826\n",
      "0.12493710754744422\n",
      "0.12482732227736792\n",
      "0.12471786317174315\n",
      "0.1246087288927621\n",
      "0.12449991810869393\n",
      "0.12439142949385269\n",
      "0.12428326172856541\n",
      "0.12417541349914622\n",
      "0.12406788349786985\n",
      "0.12396067042293751\n",
      "0.12385377297845072\n",
      "0.12374718987438305\n",
      "0.12364091982655513\n",
      "0.12353496155659709\n",
      "0.12342931379193267\n",
      "0.12332397526573939\n",
      "0.12321894471693313\n",
      "0.12311422089012704\n",
      "0.12300980253561637\n",
      "0.12290568840934199\n",
      "0.12280187727287156\n",
      "0.12269836789336408\n",
      "0.12259515904354959\n",
      "0.12249224950169732\n",
      "0.12238963805159324\n",
      "0.12228732348251065\n",
      "0.12218530458918764\n",
      "0.12208358017179419\n",
      "0.1219821490359128\n",
      "0.12188100999251066\n",
      "0.12178016185790881\n",
      "0.1216796034537676\n",
      "0.12157933360704547\n",
      "0.12147935114999116\n",
      "0.12137965492010136\n",
      "0.12128024376010983\n",
      "0.12118111651795292\n",
      "0.12108227204674746\n",
      "0.12098370920477042\n",
      "0.12088542685542464\n",
      "0.1207874238672232\n",
      "0.12068969911376212\n",
      "0.12059225147369362\n",
      "0.12049507983070346\n",
      "0.12039818307349076\n",
      "0.12030156009573578\n",
      "0.12020520979608712\n",
      "0.12010913107812543\n",
      "0.12001332285034912\n",
      "0.11991778402614808\n",
      "0.11982251352378205\n",
      "0.1197275102663511\n",
      "0.11963277318178307\n",
      "0.1195383012027969\n",
      "0.1194440932668947\n",
      "0.1193501483163283\n",
      "0.11925646529807979\n",
      "0.1191630431638414\n",
      "0.11906988086998843\n",
      "0.11897697737756036\n",
      "0.11888433165223806\n",
      "0.11879194266432096\n",
      "0.11869980938870671\n",
      "0.11860793080486566\n",
      "0.11851630589682378\n",
      "0.11842493365313815\n",
      "0.11833381306687578\n",
      "0.11824294313559315\n",
      "0.11815232286131268\n",
      "0.11806195125050493\n",
      "0.11797182731406526\n",
      "0.1178819500672915\n",
      "0.11779231852986721\n",
      "0.11770293172583796\n",
      "0.11761378868358807\n",
      "0.11752488843582726\n",
      "0.11743623001956374\n",
      "0.11734781247608712\n",
      "0.11725963485094591\n",
      "0.11717169619392986\n",
      "0.117083995559048\n",
      "0.1169965320045092\n",
      "0.11690930459270193\n",
      "0.11682231239017568\n",
      "0.11673555446762011\n",
      "0.1166490298998458\n",
      "0.11656273776576478\n",
      "0.11647667714837251\n",
      "0.11639084713472478\n",
      "0.11630524681592333\n",
      "0.11621987528709397\n",
      "0.1161347316473666\n",
      "0.11604981499985972\n",
      "0.11596512445165895\n",
      "0.11588065911379737\n",
      "0.11579641810124254\n",
      "0.1157124005328698\n",
      "0.1156286055314518\n",
      "0.11554503222363215\n",
      "0.1154616797399161\n",
      "0.11537854721464194\n",
      "0.11529563378597531\n",
      "0.11521293859587951\n",
      "0.11513046079010622\n",
      "0.11504819951817001\n",
      "0.11496615393333881\n",
      "0.11488432319260887\n",
      "0.11480270645669317\n",
      "0.11472130289000118\n",
      "0.114640111660619\n",
      "0.11455913194029813\n",
      "0.11447836290443215\n",
      "0.11439780373204489\n",
      "0.11431745360576764\n",
      "0.11423731171182842\n",
      "0.11415737724003135\n",
      "0.1140776493837382\n",
      "0.11399812733985885\n",
      "0.11391881030882564\n",
      "0.11383969749458293\n",
      "0.11376078810456955\n",
      "0.11368208134969933\n",
      "0.11360357644435033\n",
      "0.1135252726063434\n",
      "0.11344716905692916\n",
      "0.1133692650207711\n",
      "0.11329155972592768\n",
      "0.11321405240384035\n",
      "0.11313674228931601\n",
      "0.11305962862050858\n",
      "0.11298271063890801\n",
      "0.11290598758932108\n",
      "0.11282945871985811\n",
      "0.11275312328191411\n",
      "0.11267698053016068\n",
      "0.11260102972252055\n",
      "0.11252527012016186\n",
      "0.11244970098747777\n",
      "0.11237432159207261\n",
      "0.11229913120474626\n",
      "0.11222412909948021\n",
      "0.11214931455342421\n",
      "0.11207468684687792\n",
      "0.11200024526327754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11192598908918243\n",
      "0.1118519176142622\n",
      "0.11177803013127623\n",
      "0.1117043259360646\n",
      "0.11163080432753304\n",
      "0.11155746460763544\n",
      "0.11148430608136498\n",
      "0.1114113280567325\n",
      "0.11133852984476227\n",
      "0.11126591075946902\n",
      "0.11119347011785068\n",
      "0.11112120723986722\n",
      "0.11104912144843454\n",
      "0.1109772120694074\n",
      "0.1109054784315644\n",
      "0.11083391986659659\n",
      "0.11076253570909286\n",
      "0.11069132529652799\n",
      "0.11062028796924624\n",
      "0.11054942307045103\n",
      "0.11047872994619057\n",
      "0.11040820794534484\n",
      "0.1103378564196104\n",
      "0.11026767472349279\n",
      "0.11019766221428814\n",
      "0.11012781825206927\n",
      "0.11005814219968202\n",
      "0.10998863342272043\n",
      "0.10991929128952202\n",
      "0.10985011517115331\n",
      "0.10978110444139456\n",
      "0.10971225847673204\n",
      "0.10964357665634092\n",
      "0.1095750583620747\n",
      "0.1095067029784537\n",
      "0.10943850989265255\n",
      "0.10937047849448413\n",
      "0.10930260817639523\n",
      "0.10923489833344684\n",
      "0.10916734836330441\n",
      "0.10909995766622844\n",
      "0.1090327256450599\n",
      "0.10896565170520744\n",
      "0.10889873525463867\n",
      "0.10883197570386786\n",
      "0.10876537246593954\n",
      "0.10869892495642304\n",
      "0.10863263259339839\n",
      "0.10856649479744258\n",
      "0.10850051099162286\n",
      "0.10843468060148041\n",
      "0.10836900305502113\n",
      "0.1083034777827065\n",
      "0.10823810421743599\n",
      "0.10817288179454473\n",
      "0.10810780995178312\n",
      "0.10804288812931295\n",
      "0.1079781157696927\n",
      "0.10791349231786788\n",
      "0.10784901722115771\n",
      "0.10778468992924803\n",
      "0.10772050989417768\n",
      "0.10765647657032729\n",
      "0.10759258941441288\n",
      "0.1075288478854679\n",
      "0.1074652514448407\n",
      "0.10740179955617649\n",
      "0.10733849168541287\n",
      "0.10727532730076558\n",
      "0.10721230587271861\n",
      "0.10714942687401689\n",
      "0.10708668977964826\n",
      "0.10702409406684608\n",
      "0.10696163921506383\n",
      "0.10689932470597707\n",
      "0.10683715002346651\n",
      "0.10677511465361213\n",
      "0.10671321808467903\n",
      "0.10665145980710872\n",
      "0.10658983931351293\n",
      "0.10652835609865846\n",
      "0.10646700965946043\n",
      "0.10640579949497199\n",
      "0.1063447251063722\n",
      "0.10628378599696134\n",
      "0.10622298167214425\n",
      "0.10616231163942974\n",
      "0.10610177540841194\n",
      "0.10604137249076605\n",
      "0.10598110240023813\n",
      "0.1059209646526342\n",
      "0.10586095876581304\n",
      "0.10580108425967472\n",
      "0.10574134065615286\n",
      "0.105681727479203\n",
      "0.10562224425479788\n",
      "0.10556289051091336\n",
      "0.10550366577752318\n",
      "0.10544456958658555\n",
      "0.10538560147203967\n",
      "0.10532676096979153\n",
      "0.10526804761770885\n",
      "0.10520946095560946\n",
      "0.1051510005252542\n",
      "0.10509266587033779\n",
      "0.1050344565364783\n",
      "0.10497637207121072\n",
      "0.10491841202397738\n",
      "0.10486057594611947\n",
      "0.10480286339086844\n",
      "0.10474527391333528\n",
      "0.10468780707050736\n",
      "0.10463046242123403\n",
      "0.10457323952622097\n",
      "0.10451613794802168\n",
      "0.10445915725102996\n",
      "0.10440229700146932\n",
      "0.10434555676738583\n",
      "0.10428893611864161\n",
      "0.10423243462690249\n",
      "0.10417605186563442\n",
      "0.10411978741009315\n",
      "0.10406364083731523\n",
      "0.10400761172611034\n",
      "0.1039516996570552\n",
      "0.10389590421248704\n",
      "0.10384022497648589\n",
      "0.10378466153488053\n",
      "0.10372921347522968\n",
      "0.10367388038682131\n",
      "0.10361866186065892\n",
      "0.10356355748945875\n",
      "0.10350856686763936\n",
      "0.10345368959131453\n",
      "0.10339892525828603\n",
      "0.1033442734680355\n",
      "0.10328973382171819\n",
      "0.10323530592215124\n",
      "0.10318098937381373\n",
      "0.10312678378283131\n",
      "0.1030726887569728\n",
      "0.10301870390564445\n",
      "0.10296482883987777\n",
      "0.10291106317232454\n",
      "0.10285740651725385\n",
      "0.10280385849053558\n",
      "0.10275041870964169\n",
      "0.1026970867936353\n",
      "0.10264386236316268\n",
      "0.1025907450404489\n",
      "0.10253773444928911\n",
      "0.10248483021504032\n",
      "0.10243203196461664\n",
      "0.10237933932648288\n",
      "0.10232675193064404\n",
      "0.10227426940864112\n",
      "0.10222189139354204\n",
      "0.1021696175199406\n",
      "0.10211744742394138\n",
      "0.10206538074315845\n",
      "0.10201341711670772\n",
      "0.10196155618519807\n",
      "0.10190979759072814\n",
      "0.10185814097687595\n",
      "0.10180658598869585\n",
      "0.1017551322727095\n",
      "0.10170377947689889\n",
      "0.1016525272507013\n",
      "0.10160137524500538\n",
      "0.10155032311213699\n",
      "0.10149937050586043\n",
      "0.10144851708136836\n",
      "0.10139776249527642\n",
      "0.10134710640561582\n",
      "0.10129654847182869\n",
      "0.10124608835476008\n",
      "0.10119572571665329\n",
      "0.10114546022114199\n",
      "0.10109529153324538\n",
      "0.10104521931936176\n",
      "0.10099524324726225\n",
      "0.10094536298608303\n",
      "0.10089557820632299\n",
      "0.10084588857983386\n",
      "0.10079629377981653\n",
      "0.10074679348081432\n",
      "0.10069738735870715\n",
      "0.10064807509070446\n",
      "0.10059885635534067\n",
      "0.1005497308324699\n",
      "0.10050069820325837\n",
      "0.10045175815017961\n",
      "0.10040291035700762\n",
      "0.10035415450881217\n",
      "0.10030549029195295\n",
      "0.10025691739407384\n",
      "0.10020843550409601\n",
      "0.10016004431221438\n",
      "0.10011174350988955\n",
      "0.10006353278984455\n",
      "0.10001541184605776\n",
      "0.09996738037375764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.4786387208196003, 2.0320563576637283, 4.72523869171243, 12.31866173903713, 18.97919911802692, 17.660759956511438, 22.669259879669397, 17.921098216933053, 22.46384112254556, 17.60610490168276  …  0.5721430992455032, 0.5721323657290442, 0.5721216378986319, 0.5721109157440384, 0.5721001992550658, 0.5720894884215548, 0.5720787832333766, 0.5720680836804327, 0.5720573897526589, 0.5720467014400251], 1.3983071749485456, [0.049992270636727065, 0.04876532269536386, 0.0909640088380426, 0.09338610109724525, 0.06097162552894454, 0.06965974608673746, 0.07435580638727404, 0.006849242226453433, -0.004000789149839729, 0.001451913508163908  …  0.0052837076300908635, 0.008339922858016264, 0.03678101547109689, 0.0011553402787611038, 0.04882193061764839, -0.0006343845805752229, 0.011566862806944892, 0.006476098579456614, 0.012492317936925462, 0.009297300554850297])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stable Reg Params and regression\n",
    "k = 100; λ=.1\n",
    "w_opt, u_opt, θ_opt, opt_obj = stable_reg_l2_reg(X, Y, λ, k)\n",
    "\n",
    "#EVaR Params and regression\n",
    "α = 1 - k/n; c_s=0.001; c_w=0.0001; ε=0.1; w_0=ones(p)./100; s_0 = .9\n",
    "list_f, s, w_EVaR = gradient_descent_EVaR_ℓ2(X,Y,s_0,w_0,α,c_s,c_w,ε)\n",
    "\n",
    "c_s=0.0001; c_w=0.0001; w_0=w_EVaR; s_0 = s; ε = 0.01\n",
    "list_f2, s2, w_EVaR2 = gradient_descent_EVaR_ℓ2(X,Y,s_0,w_0,α,c_s,c_w,ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T19:07:14.906000-05:00",
     "start_time": "2019-12-02T00:07:14.891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training scores are : \n",
      " The RMSE for the EVaR Regression is for ϵ = 0.1 : 0.5341719564132272\n",
      " The RMSE for the EVaR Regression is for ϵ = 0.01 : 0.5062091960729718\n",
      " The RMSE for the Stable Regression is : 0.5181819613399516\n",
      "\n",
      " The test scores are : \n",
      " The RMSE for the EVaR Regression is for ϵ = 0.1 : 0.540600241274734\n",
      " The RMSE for the EVaR Regression is for ϵ = 0.01 : 0.549493304579194\n",
      " The RMSE for the Stable Regression is : 0.5694343039816557\n"
     ]
    }
   ],
   "source": [
    "println(\" The training scores are : \")\n",
    "println(\" The RMSE for the EVaR Regression is for ε = 0.1 : \", sqrt(mean((X*w_EVaR-Y).^2)))\n",
    "println(\" The RMSE for the EVaR Regression is for ε = 0.01 : \", sqrt(mean((X*w_EVaR2-Y).^2)))\n",
    "println(\" The RMSE for the Stable Regression is : \", sqrt(mean((X*w_opt-Y).^2)))\n",
    "println(\"\\n The test scores are : \")\n",
    "println(\" The RMSE for the EVaR Regression is for ε = 0.1 : \", sqrt(mean((X_test*w_EVaR-Y_test).^2)))\n",
    "println(\" The RMSE for the EVaR Regression is for ε = 0.01 : \", sqrt(mean((X_test*w_EVaR2-Y_test).^2)))\n",
    "println(\" The RMSE for the Stable Regression is : \", sqrt(mean((X_test*w_opt-Y_test).^2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T22:01:27.102000-05:00",
     "start_time": "2019-12-02T03:01:27.064Z"
    },
    "scrolled": true
   },
   "source": [
    "### Some observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see below that the optimal vectors are quite different, we sometimes obtain regression coefficients with ≠ signs! However the MSE etc... Are quite close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T22:02:43.730000-05:00",
     "start_time": "2019-12-02T03:02:43.726Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42-element Array{Float64,1}:\n",
       "  0.10207108061902605   \n",
       " -0.021066134651967227  \n",
       "  0.015463953398501989  \n",
       " -0.008722611234819355  \n",
       "  0.11526387636966555   \n",
       " -0.03960455868062739   \n",
       "  0.20063829414568468   \n",
       "  0.003577525539958179  \n",
       " -0.009101022984684905  \n",
       " -0.08939386826088667   \n",
       " -0.14103048284917014   \n",
       " -0.21210166390817953   \n",
       " -0.05831920108269209   \n",
       "  ⋮                     \n",
       " -0.11110545171028952   \n",
       " -0.14015344067599445   \n",
       "  0.2369004488529454    \n",
       "  0.3764612544687055    \n",
       "  0.33908034088253514   \n",
       "  0.36874225544267947   \n",
       "  0.3183121867082784    \n",
       "  0.32907957452564957   \n",
       "  0.45709321047677387   \n",
       "  0.32989866464434553   \n",
       "  0.41200196634720054   \n",
       " -1.4888701985398634e-10"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T22:02:33.631000-05:00",
     "start_time": "2019-12-02T03:02:33.627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42-element Array{Float64,1}:\n",
       "  0.1702023147968051   \n",
       "  0.017206104988115957 \n",
       "  0.05522081449134421  \n",
       "  0.09137378849723386  \n",
       "  0.09667402740296399  \n",
       " -0.004231651263063173 \n",
       "  0.1397252252215143   \n",
       "  0.006227402978673826 \n",
       " -0.007961425194564878 \n",
       " -0.014369307409649656 \n",
       "  0.06419308150310499  \n",
       "  0.030636275833428157 \n",
       " -0.01030161594355138  \n",
       "  ⋮                    \n",
       " -0.03459013400772386  \n",
       " -0.022672574338347958 \n",
       "  0.012134617096319356 \n",
       " -0.005041273290073722 \n",
       "  0.11936902466349952  \n",
       "  0.051221627965438485 \n",
       "  0.07499036327851458  \n",
       " -0.05410996064198774  \n",
       "  0.03918873336538251  \n",
       " -0.010292303550626221 \n",
       "  0.053872239261088556 \n",
       "  0.0019082706771125773"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_EVaR2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Craft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T17:01:39.180000-05:00",
     "start_time": "2019-12-01T22:01:39.158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cutting_planes (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 10000 #iter_max\n",
    "function cutting_planes(X,Y,α,ε)\n",
    "    list_s=[.9]; list_w=[ones(p)./100]\n",
    "    list_f = [objective_ℓ2(X,Y,list_s[1],list_w[1],α)]\n",
    "    \n",
    "    model = Model(solver=GurobiSolver())\n",
    "\n",
    "        # Optimization variables\n",
    "        @variable(model, s>=0.000001)\n",
    "        @variable(model, t>=0)\n",
    "        @variable(model, w[1:p])\n",
    "\n",
    "        # objective_ℓ2\n",
    "        @objective_ℓ2(model, Min, t)\n",
    "\n",
    "        #we use the ε formulation because otherwise we do not obtain results\n",
    "        @constraint(model, t >= objective_ℓ2(X,Y,list_s[1],list_w[1],α)+ ∇sobjective_ℓ2(X,Y,list_s[1],list_w[1],α)*(s-list_s[1]) + dot(∇wobjective_ℓ2(X,Y,list_s[1],list_w[1],α),w-list_w[1]))\n",
    "        @constraint(model, [j=1:p], w[j] >= -1)\n",
    "        @constraint(model, [j=1:p], 1 >= w[j])\n",
    "        solve(model)\n",
    "        push!(list_s, getvalue(s))\n",
    "        push!(list_w, getvalue(w))\n",
    "        t_opt = getvalue(t)\n",
    "        println(getvalue(s))\n",
    "        for k in 2:K\n",
    "            push!(list_f, objective_ℓ2(X,Y,list_s[k],list_w[k],α))\n",
    "            if t_opt + ε < list_f[k]\n",
    "                println(list_f)\n",
    "                @constraint(model, t >=objective_ℓ2(X,Y,list_s[k],list_w[k],α) + ∇sobjective_ℓ2(X,Y,list_s[k],list_w[k],α)*(s-list_s[k]) + dot(∇wobjective_ℓ2(X,Y,list_s[k],list_w[k],α),w-list_w[k]))\n",
    "                solve(model)\n",
    "                push!(list_s, getvalue(s))\n",
    "                push!(list_w, getvalue(w))\n",
    "                t_opt = getvalue(t)\n",
    "            else break\n",
    "            end\n",
    "        end\n",
    "            \n",
    "    \n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T17:01:39.910000-05:00",
     "start_time": "2019-12-01T22:01:39.329Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n",
      "Optimize a model with 87 rows, 45 columns and 131 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-03, 1e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 6e+00]\n",
      "Presolve removed 87 rows and 45 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "85.5352368782963\n",
      "[1.3250372588602282, 18061.681987688222]\n",
      "Warning for adding constraints: zero or small (< 1e-13) coefficients, ignored\n",
      "Optimize a model with 88 rows, 45 columns and 165 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.411069e+02   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691]\n",
      "Optimize a model with 89 rows, 45 columns and 203 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   8.205271e+01   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185]\n",
      "Optimize a model with 90 rows, 45 columns and 230 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   6.943124e+01   0.000000e+00      0s\n",
      "       2    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584]\n",
      "Optimize a model with 91 rows, 45 columns and 275 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   4.460802e+01   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727]\n",
      "Optimize a model with 92 rows, 45 columns and 320 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   3.454432e+01   0.000000e+00      0s\n",
      "       2    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365]\n",
      "Optimize a model with 93 rows, 45 columns and 365 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.473067e+01   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277]\n",
      "Optimize a model with 94 rows, 45 columns and 410 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.666636e+01   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739]\n",
      "Optimize a model with 95 rows, 45 columns and 455 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.960486e+01   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175]\n",
      "Optimize a model with 96 rows, 45 columns and 500 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.142356e+01   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736]\n",
      "Optimize a model with 97 rows, 45 columns and 545 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   6.798602e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535]\n",
      "Optimize a model with 98 rows, 45 columns and 590 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.372757e+01   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054]\n",
      "Optimize a model with 99 rows, 45 columns and 635 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.542204e+01   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457]\n",
      "Optimize a model with 100 rows, 45 columns and 680 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   7.112024e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064]\n",
      "Optimize a model with 101 rows, 45 columns and 725 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   5.044324e+00   0.000000e+00      0s\n",
      "       9    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 9 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063]\n",
      "Optimize a model with 102 rows, 45 columns and 770 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   6.412526e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007]\n",
      "Optimize a model with 103 rows, 45 columns and 815 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   3.433835e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147]\n",
      "Optimize a model with 104 rows, 45 columns and 860 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   4.281137e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096]\n",
      "Optimize a model with 105 rows, 45 columns and 905 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   3.642153e+00   0.000000e+00      0s\n",
      "       2    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584]\n",
      "Optimize a model with 106 rows, 45 columns and 950 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   3.526854e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527]\n",
      "Optimize a model with 107 rows, 45 columns and 995 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   5.092791e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607]\n",
      "Optimize a model with 108 rows, 45 columns and 1040 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   3.745980e+00   0.000000e+00      0s\n",
      "       2    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721]\n",
      "Optimize a model with 109 rows, 45 columns and 1085 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.162468e+01   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601]\n",
      "Optimize a model with 110 rows, 45 columns and 1130 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.223092e+01   0.000000e+00      0s\n",
      "       4    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 4 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191]\n",
      "Optimize a model with 111 rows, 45 columns and 1175 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   6.253997e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606]\n",
      "Optimize a model with 112 rows, 45 columns and 1220 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   8.753295e+00   0.000000e+00      0s\n",
      "       2    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833]\n",
      "Optimize a model with 113 rows, 45 columns and 1265 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.391633e+01   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586]\n",
      "Optimize a model with 114 rows, 45 columns and 1310 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   8.026150e+00   0.000000e+00      0s\n",
      "       2    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092]\n",
      "Optimize a model with 115 rows, 45 columns and 1355 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   6.535853e+00   0.000000e+00      0s\n",
      "       7    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 7 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584]\n",
      "Optimize a model with 116 rows, 45 columns and 1400 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   5.215066e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698]\n",
      "Optimize a model with 117 rows, 45 columns and 1445 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   8.951227e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409]\n",
      "Optimize a model with 118 rows, 45 columns and 1490 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   3.354854e+00   0.000000e+00      0s\n",
      "       6    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 6 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105]\n",
      "Optimize a model with 119 rows, 45 columns and 1535 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   5.437388e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507]\n",
      "Optimize a model with 120 rows, 45 columns and 1580 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   5.870066e+00   0.000000e+00      0s\n",
      "       4    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 4 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144]\n",
      "Optimize a model with 121 rows, 45 columns and 1625 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   5.564504e+00   0.000000e+00      0s\n",
      "       4    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 4 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816]\n",
      "Optimize a model with 122 rows, 45 columns and 1670 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.883740e+00   0.000000e+00      0s\n",
      "       2    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152]\n",
      "Optimize a model with 123 rows, 45 columns and 1715 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.517813e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856]\n",
      "Optimize a model with 124 rows, 45 columns and 1760 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   4.030768e+00   0.000000e+00      0s\n",
      "       2    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516]\n",
      "Optimize a model with 125 rows, 45 columns and 1805 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.764548e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751]\n",
      "Optimize a model with 126 rows, 45 columns and 1850 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   3.129516e+00   0.000000e+00      0s\n",
      "       2    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004]\n",
      "Optimize a model with 127 rows, 45 columns and 1895 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.199054e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284]\n",
      "Optimize a model with 128 rows, 45 columns and 1940 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.987500e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392]\n",
      "Optimize a model with 129 rows, 45 columns and 1985 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.796769e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345]\n",
      "Optimize a model with 130 rows, 45 columns and 2030 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.598739e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782]\n",
      "Optimize a model with 131 rows, 45 columns and 2075 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.785074e+00   0.000000e+00      0s\n",
      "       7    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 7 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931]\n",
      "Optimize a model with 132 rows, 45 columns and 2120 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.481914e+00   0.000000e+00      0s\n",
      "       3    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 3 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772]\n",
      "Optimize a model with 133 rows, 45 columns and 2165 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.977880e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimize a model with 134 rows, 45 columns and 2210 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.505066e+00   0.000000e+00      0s\n",
      "      12    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 12 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884, 8.842414527998924]\n",
      "Optimize a model with 135 rows, 45 columns and 2255 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.210604e+00   0.000000e+00      0s\n",
      "       3    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 3 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884, 8.842414527998924, 10.483858164412354]\n",
      "Optimize a model with 136 rows, 45 columns and 2300 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.620965e+00   0.000000e+00      0s\n",
      "       2    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884, 8.842414527998924, 10.483858164412354, 6.102830349608161]\n",
      "Optimize a model with 137 rows, 45 columns and 2345 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.525708e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884, 8.842414527998924, 10.483858164412354, 6.102830349608161, 30.102846871555023]\n",
      "Optimize a model with 138 rows, 45 columns and 2390 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.881428e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884, 8.842414527998924, 10.483858164412354, 6.102830349608161, 30.102846871555023, 9.508267162679825]\n",
      "Optimize a model with 139 rows, 45 columns and 2435 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.377067e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884, 8.842414527998924, 10.483858164412354, 6.102830349608161, 30.102846871555023, 9.508267162679825, 5.519771835883941]\n",
      "Optimize a model with 140 rows, 45 columns and 2480 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   1.379943e+00   0.000000e+00      0s\n",
      "       2    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884, 8.842414527998924, 10.483858164412354, 6.102830349608161, 30.102846871555023, 9.508267162679825, 5.519771835883941, 4.554584011640497]\n",
      "Optimize a model with 141 rows, 45 columns and 2525 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.277292e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884, 8.842414527998924, 10.483858164412354, 6.102830349608161, 30.102846871555023, 9.508267162679825, 5.519771835883941, 4.554584011640497, 4.568833375717055]\n",
      "Optimize a model with 142 rows, 45 columns and 2570 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.284417e+00   0.000000e+00      0s\n",
      "       7    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 7 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884, 8.842414527998924, 10.483858164412354, 6.102830349608161, 30.102846871555023, 9.508267162679825, 5.519771835883941, 4.554584011640497, 4.568833375717055, 10.244045532959134]\n",
      "Optimize a model with 143 rows, 45 columns and 2615 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   5.122023e+00   0.000000e+00      0s\n",
      "       5    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 5 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884, 8.842414527998924, 10.483858164412354, 6.102830349608161, 30.102846871555023, 9.508267162679825, 5.519771835883941, 4.554584011640497, 4.568833375717055, 10.244045532959134, 6.684865391896348]\n",
      "Optimize a model with 144 rows, 45 columns and 2660 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   3.342433e+00   0.000000e+00      0s\n",
      "       2    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 2 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884, 8.842414527998924, 10.483858164412354, 6.102830349608161, 30.102846871555023, 9.508267162679825, 5.519771835883941, 4.554584011640497, 4.568833375717055, 10.244045532959134, 6.684865391896348, 6.82554344597449]\n",
      "Optimize a model with 145 rows, 45 columns and 2705 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   3.412772e+00   0.000000e+00      0s\n",
      "       1    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 1 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884, 8.842414527998924, 10.483858164412354, 6.102830349608161, 30.102846871555023, 9.508267162679825, 5.519771835883941, 4.554584011640497, 4.568833375717055, 10.244045532959134, 6.684865391896348, 6.82554344597449, 5.124565638825845]\n",
      "Optimize a model with 146 rows, 45 columns and 2750 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   2.562283e+00   0.000000e+00      0s\n",
      "       3    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 3 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884, 8.842414527998924, 10.483858164412354, 6.102830349608161, 30.102846871555023, 9.508267162679825, 5.519771835883941, 4.554584011640497, 4.568833375717055, 10.244045532959134, 6.684865391896348, 6.82554344597449, 5.124565638825845, 3.602676019269857]\n",
      "Optimize a model with 147 rows, 45 columns and 2795 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   3.602676e+00   0.000000e+00      0s\n",
      "       9    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 9 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884, 8.842414527998924, 10.483858164412354, 6.102830349608161, 30.102846871555023, 9.508267162679825, 5.519771835883941, 4.554584011640497, 4.568833375717055, 10.244045532959134, 6.684865391896348, 6.82554344597449, 5.124565638825845, 3.602676019269857, 4.778981047623544]\n",
      "Optimize a model with 148 rows, 45 columns and 2840 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-13, 2e+04]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e-06, 1e-06]\n",
      "  RHS range        [1e+00, 2e+04]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    0.0000000e+00   4.778981e+00   0.000000e+00      0s\n",
      "       5    0.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 5 iterations and 0.00 seconds\n",
      "Optimal objective  0.000000000e+00\n",
      "[1.3250372588602282, 18061.681987688222, 5251.37367731691, 2221.7996186785185, 1427.4566693411584, 552.7091906537727, 395.69072075713365, 426.66173619905277, 156.8388916901739, 91.38850161850175, 54.38881472530736, 439.28218765419535, 123.37633185770054, 56.89619496160457, 40.354591497270064, 51.30020421975063, 27.470682201246007, 68.4981957861147, 29.137225584128096, 56.429660458023584, 20.371163746267527, 14.98391882658607, 92.9974325479721, 48.92366053817601, 50.0319725961191, 35.013179711249606, 55.66533727366833, 32.10459979485586, 26.14341295266092, 20.860264617668584, 35.80490922251698, 13.41941632526409, 43.499107658567105, 23.480262032716507, 22.25801761989144, 46.139841424302816, 24.28501513323152, 16.12307279159856, 11.05819257001516, 12.518065983363751, 8.796216091672004, 7.950001276326284, 7.187076992301392, 10.394955532298345, 11.140295807174782, 9.927657108921931, 7.91151932388772, 6.020263506487884, 8.842414527998924, 10.483858164412354, 6.102830349608161, 30.102846871555023, 9.508267162679825, 5.519771835883941, 4.554584011640497, 4.568833375717055, 10.244045532959134, 6.684865391896348, 6.82554344597449, 5.124565638825845, 3.602676019269857, 4.778981047623544, Inf]\n"
     ]
    },
    {
     "ename": "ErrorException",
     "evalue": "Invalid coefficient NaN on variable s",
     "output_type": "error",
     "traceback": [
      "Invalid coefficient NaN on variable s",
      "",
      "Stacktrace:",
      " [1] error(::String) at /Applications/Julia-1.2.app/Contents/Resources/julia/lib/julia/sys.dylib:?",
      " [2] assert_isfinite at /Users/iai/builds/InterpretableAI/SysImgBuilder/.julia/packages/JuMP/I7whV/src/affexpr.jl:124 [inlined]",
      " [3] addconstraint(::Model, ::JuMP.GenericRangeConstraint{JuMP.GenericAffExpr{Float64,Variable}}) at /Users/iai/builds/InterpretableAI/SysImgBuilder/.julia/packages/JuMP/I7whV/src/affexpr.jl:207",
      " [4] macro expansion at /Users/iai/builds/InterpretableAI/SysImgBuilder/.julia/packages/JuMP/I7whV/src/macros.jl:494 [inlined]",
      " [5] cutting_planes(::Array{Float64,2}, ::Array{Float64,2}, ::Float64, ::Float64) at ./In[10]:29",
      " [6] top-level scope at In[11]:1"
     ]
    }
   ],
   "source": [
    "cutting_planes(X,Y,.95,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
